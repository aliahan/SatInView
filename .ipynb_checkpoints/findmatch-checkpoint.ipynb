{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809583cb-b5df-41ff-832c-1af7c2940e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def process_observed_data(filename):\n",
    "    data = pd.read_csv(filename, sep=',', header=None, names=['Timestamp', 'Y', 'X'])\n",
    "    data['Timestamp'] = pd.to_datetime(data['Timestamp'], utc=True)\n",
    "    \n",
    "    observer_x, observer_y = 62, 62 - (27.1 / (80/62))  # Assume this is the observer's pixel location\n",
    "    pixel_to_degrees = (80/62)  # Conversion factor from pixel to degrees\n",
    "    \n",
    "    positions = []\n",
    "    for index, point in data.iterrows():\n",
    "        dx, dy = point['X'] - observer_x, point['Y'] - observer_y\n",
    "        radius = np.sqrt(dx**2 + dy**2) * pixel_to_degrees\n",
    "        azimuth = np.degrees(np.arctan2(dx, dy))\n",
    "        # Normalize the azimuth to ensure it's within 0 to 360 degrees\n",
    "        azimuth = (azimuth + 360) % 360\n",
    "        elevation = 90 - radius\n",
    "        positions.append((point['Timestamp'], point['Y'], point['X'], elevation, azimuth))\n",
    "    \n",
    "    df_positions = pd.DataFrame(positions, columns=['Timestamp', 'Y', 'X', 'Elevation', 'Azimuth'])\n",
    "    return df_positions\n",
    "\n",
    "def main(filename):\n",
    "    observed_positions = process_observed_data(filename)\n",
    "    if not observed_positions.empty:\n",
    "        print(observed_positions)\n",
    "        observed_positions.to_csv('processed_observed_data_bri.csv', index=False)\n",
    "    else:\n",
    "        print(\"No valid observed data found.\")\n",
    "    return observed_positions\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    filename = 'white_pixel_coordinates_bri.csv'\n",
    "    observed_positions = main(filename)\n",
    "    observed_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199e4cf3-d064-46e9-85d1-73f7293578ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skyfield.api import load, wgs84, utc\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "\n",
    "def load_data():\n",
    "    stations_url = 'https://celestrak.org/NORAD/elements/gp.php?GROUP=starlink&FORMAT=tle'\n",
    "    satellites = load.tle_file(stations_url)\n",
    "    return satellites\n",
    "\n",
    "def set_observation_time(year, month, day, hour, minute, second):\n",
    "    ts = load.timescale()\n",
    "    return ts.utc(year, month, day, hour, minute, second)\n",
    "\n",
    "def process_observed_data(filename, start_time, merged_data_file):\n",
    "    data = pd.read_csv(filename, sep=',', header=None, names=['Timestamp', 'Y', 'X'])\n",
    "    data['Timestamp'] = pd.to_datetime(data['Timestamp'], utc=True)\n",
    "    interval_start_time = pd.to_datetime(start_time, utc=True)\n",
    "    interval_end_time = interval_start_time + pd.Timedelta(seconds=14)\n",
    "    filtered_data = data[(data['Timestamp'] >= interval_start_time) & (data['Timestamp'] < interval_end_time)]\n",
    "    if filtered_data.empty:\n",
    "        print(\"No data found.\")\n",
    "        return None\n",
    "\n",
    "    merged_data = pd.read_csv(merged_data_file, parse_dates=['Timestamp'])\n",
    "    merged_data['Timestamp'] = pd.to_datetime(merged_data['Timestamp'], utc=True)\n",
    "    merged_filtered_data = merged_data[(merged_data['Timestamp'] >= interval_start_time) & (merged_data['Timestamp'] < interval_end_time)]\n",
    "    \n",
    "    if merged_filtered_data.empty:\n",
    "        print(\"No matching data found in merged_data_file.\")\n",
    "        return None\n",
    "\n",
    "    if len(merged_filtered_data) < 3:\n",
    "        print(\"Not enough data points in merged_filtered_data.\")\n",
    "        return None\n",
    "\n",
    "    start_data = merged_filtered_data.iloc[0]\n",
    "    middle_data = merged_filtered_data.iloc[len(merged_filtered_data)//2]\n",
    "    end_data = merged_filtered_data.iloc[-2]\n",
    "    rotation = 159\n",
    "    positions = [\n",
    "        (start_data['Timestamp'], (90-start_data['Elevation'], start_data['Azimuth']+ Rotation)),\n",
    "        (middle_data['Timestamp'], (90-middle_data['Elevation'], middle_data['Azimuth']+Rotation)),\n",
    "        (end_data['Timestamp'], (90-end_data['Elevation'], end_data['Azimuth']+Rotation))\n",
    "    ]\n",
    "    \n",
    "    return positions\n",
    "\n",
    "def calculate_positions_for_satellite(satellite, observer_location, start_time, interval_seconds, step_seconds):\n",
    "    ts = load.timescale()\n",
    "    positions = []\n",
    "    for second in range(0, interval_seconds + 1, step_seconds):\n",
    "        current_time = start_time + timedelta(seconds=second)\n",
    "        difference = satellite - observer_location\n",
    "        topocentric = difference.at(current_time)\n",
    "        alt, az, distance = topocentric.altaz()\n",
    "        if alt.degrees > 20:\n",
    "            positions.append((alt.degrees, az.degrees))\n",
    "    return positions\n",
    "\n",
    "def calculate_direction_vector(point1, point2):\n",
    "    \"\"\"Calculate the direction vector from point1 to point2.\"\"\"\n",
    "    alt_diff = point2[0] - point1[0]\n",
    "    az_diff = azimuth_difference(point2[1], point1[1])\n",
    "    magnitude = math.sqrt(alt_diff**2 + az_diff**2)\n",
    "    return (alt_diff / magnitude, az_diff / magnitude) if magnitude != 0 else (0, 0)\n",
    "\n",
    "def azimuth_difference(az1, az2):\n",
    "    \"\"\"Calculate the smallest difference between two azimuth angles.\"\"\"\n",
    "    diff = abs(az1 - az2) % 360\n",
    "    if diff > 180:\n",
    "        diff = 360 - diff\n",
    "    return diff\n",
    "\n",
    "def calculate_trajectory_distance(observed_positions, satellite_positions):\n",
    "    \"\"\"Calculate the distance measure between observed and satellite trajectories.\"\"\"\n",
    "    altitude_range = 90.0  # Maximum possible altitude difference\n",
    "    azimuth_range = 180.0  # Maximum possible azimuth difference\n",
    "    direction_range = 2.0  # Maximum possible direction difference (since vectors are normalized)\n",
    "    \n",
    "    distance = 0\n",
    "    for i in range(len(observed_positions)):\n",
    "        # Calculate distance between points\n",
    "        alt_deviation = abs(observed_positions[i][0] - satellite_positions[i][0]) / altitude_range\n",
    "        az_deviation = azimuth_difference(observed_positions[i][1], satellite_positions[i][1]) / azimuth_range\n",
    "        distance += alt_deviation + az_deviation\n",
    "    \n",
    "    # Calculate the overall direction vectors\n",
    "    obs_dir_vector = calculate_direction_vector(observed_positions[0], observed_positions[-1])\n",
    "    sat_dir_vector = calculate_direction_vector(satellite_positions[0], satellite_positions[len(observed_positions) - 1])\n",
    "    \n",
    "    # Calculate direction difference\n",
    "    direction_diff = math.sqrt((obs_dir_vector[0] - sat_dir_vector[0])**2 + (obs_dir_vector[1] - sat_dir_vector[1])**2) / direction_range\n",
    "    \n",
    "    # Add the direction difference to the distance measure\n",
    "    total_distance = distance + direction_diff\n",
    "    \n",
    "    return total_distance\n",
    "\n",
    "def find_matching_satellites(satellites, observer_location, observed_positions_with_timestamps):\n",
    "    best_match = None\n",
    "    closest_distance = float('inf')\n",
    "\n",
    "    ts = load.timescale()\n",
    "    \n",
    "    for satellite in satellites:\n",
    "        satellite_positions = []\n",
    "        valid_positions = True\n",
    "        \n",
    "        for observed_time, observed_data in observed_positions_with_timestamps:\n",
    "            # Calculate satellite position at the specific observed timestamp\n",
    "            difference = satellite - observer_location\n",
    "            topocentric = difference.at(ts.utc(observed_time.year, observed_time.month, observed_time.day, observed_time.hour, observed_time.minute, observed_time.second))\n",
    "            alt, az, _ = topocentric.altaz()\n",
    "            \n",
    "            if alt.degrees <= 20:\n",
    "                valid_positions = False\n",
    "                break\n",
    "            \n",
    "            satellite_positions.append((alt.degrees, az.degrees))\n",
    "        \n",
    "        if valid_positions:\n",
    "            total_distance = calculate_trajectory_distance(\n",
    "                [(90 - data[0], data[1]) for _, data in observed_positions_with_timestamps], \n",
    "                satellite_positions\n",
    "            )\n",
    "            \n",
    "            if total_distance < closest_distance:\n",
    "                closest_distance = total_distance\n",
    "                best_match = satellite.name\n",
    "    \n",
    "    return [best_match] if best_match else []\n",
    "\n",
    "def calculate_distance_for_best_match(satellite, observer_location, start_time, interval_seconds):\n",
    "    ts = load.timescale()\n",
    "    distances = []\n",
    "    for second in range(0, interval_seconds + 1):\n",
    "        current_time = start_time + timedelta(seconds=second)\n",
    "        difference = satellite - observer_location\n",
    "        topocentric = difference.at(current_time)\n",
    "        distance = topocentric.distance().km\n",
    "        distances.append(distance)\n",
    "    return distances\n",
    "\n",
    "def main(filename, year, month, day, hour, minute, second, merged_data_file, satellites):\n",
    "    initial_time = set_observation_time(year, month, day, hour, minute, second)\n",
    "    observer_location = wgs84.latlon(latitude_degrees=48.461195499999974, longitude_degrees=-123.31172833333332, elevation_m=73)\n",
    "    observed_positions_with_timestamps = process_observed_data(filename, initial_time.utc_strftime('%Y-%m-%dT%H:%M:%SZ'), merged_data_file)\n",
    "    if observed_positions_with_timestamps is None:\n",
    "        return [], [], []\n",
    "\n",
    "    matching_satellites = find_matching_satellites(satellites, observer_location, observed_positions_with_timestamps)\n",
    "    if not matching_satellites:\n",
    "        return observed_positions_with_timestamps, [], []\n",
    "\n",
    "    best_match_satellite = next(sat for sat in satellites if sat.name == matching_satellites[0])\n",
    "    distances = calculate_distance_for_best_match(best_match_satellite, observer_location, initial_time, 14)\n",
    "    \n",
    "    return observed_positions_with_timestamps, matching_satellites, distances\n",
    "\n",
    "def process_intervals(filename, start_year, start_month, start_day, start_hour, start_minute, start_second, end_year, end_month, end_day, end_hour, end_minute, end_second, merged_data_file, satellites):\n",
    "    results = []\n",
    "    \n",
    "    start_time = datetime(start_year, start_month, start_day, start_hour, start_minute, start_second, tzinfo=utc)\n",
    "    end_time = datetime(end_year, end_month, end_day, end_hour, end_minute, end_second, tzinfo=utc)\n",
    "    current_time = start_time\n",
    "    \n",
    "    while current_time <= end_time:\n",
    "        print(f\"Processing data for {current_time}\")\n",
    "        observed_positions_with_timestamps, matching_satellites, distances = main(filename, current_time.year, current_time.month, current_time.day, current_time.hour, current_time.minute, current_time.second, merged_data_file, satellites)\n",
    "        if matching_satellites:\n",
    "            for second in range(15):\n",
    "                if second < len(distances):\n",
    "                    results.append({\n",
    "                        'Timestamp': current_time + timedelta(seconds=second),\n",
    "                        'Connected_Satellite': matching_satellites[0],\n",
    "                        'Distance': distances[second]\n",
    "                    })\n",
    "        current_time += timedelta(seconds=15)\n",
    "    \n",
    "    result_df = pd.DataFrame(results)\n",
    "    return result_df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    filename = 'white_pixel_coordinates_xor714.csv'\n",
    "    merged_data_file = 'merged_data714.csv'\n",
    "    \n",
    "    # Load satellite data once\n",
    "    satellites = load_data()\n",
    "    \n",
    "    # Process intervals for the specified range of timestamps\n",
    "    result_df = process_intervals(filename, 2024, 7, 14,  16, 5,42, 2024, 7, 15,  4, 35,27, merged_data_file, satellites)\n",
    "\n",
    "    # Load the data from both CSV files\n",
    "    merged_data_df = pd.read_csv('merged_data714.csv', parse_dates=['Timestamp'])\n",
    "\n",
    "    # Load the existing matched_satellite_data.csv if it exists\n",
    "    if os.path.exists('first.csv'):\n",
    "        existing_df = pd.read_csv('first.csv', parse_dates=['Timestamp'])\n",
    "    else:\n",
    "        existing_df = pd.DataFrame()\n",
    "\n",
    "    # Merge the dataframes on Timestamp column\n",
    "    merged_df = pd.merge(merged_data_df, result_df, on='Timestamp', how='inner')\n",
    "\n",
    "    # Append the new data to the existing data\n",
    "    updated_df = pd.concat([existing_df, merged_df]).drop_duplicates(subset=['Timestamp'], keep='last')\n",
    "\n",
    "    # Save the updated dataframe to the CSV file\n",
    "    updated_df.to_csv('first.csv', index=False)\n",
    "\n",
    "    print(\"Updated data saved to 'matched_satellite_data_new.csv'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
