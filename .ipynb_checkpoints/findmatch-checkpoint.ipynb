{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6359b338-89e4-4f92-b28c-193990e9b4b8",
   "metadata": {},
   "source": [
    "# please fill this cell before runnig all cells "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f40723f-0562-41ad-a7af-c34885e40e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# your UT's orientation\n",
    "_tilt =12\n",
    "_rotation_az =-1\n",
    "_lat=111\n",
    "_lon=-35\n",
    "_alt=60\n",
    "# Srart of first 15 second interval\n",
    "_first_year=2024\n",
    "_first_month=8\n",
    "_first_day=16\n",
    "_first_hour=20\n",
    "_first_minute=32\n",
    "_first_second=12\n",
    "# Srart of last 15 second interval\n",
    "_last_year=2024\n",
    "_last_month=8\n",
    "_last_day=16\n",
    "_last_hour=22\n",
    "_last_minute=35\n",
    "_last_second=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809583cb-b5df-41ff-832c-1af7c2940e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def process_observed_data(filename):\n",
    "    data = pd.read_csv(filename, sep=',', header=None, names=['Timestamp', 'Y', 'X'])\n",
    "    data['Timestamp'] = pd.to_datetime(data['Timestamp'], utc=True)\n",
    "    \n",
    "    observer_x, observer_y = 62, 62 - (_tilt / (80/62))  # Assume this is the observer's pixel location\n",
    "    pixel_to_degrees = (80/62)  # Conversion factor from pixel to degrees\n",
    "    \n",
    "    positions = []\n",
    "    for index, point in data.iterrows():\n",
    "        dx, dy = point['X'] - observer_x, point['Y'] - observer_y\n",
    "        radius = np.sqrt(dx**2 + dy**2) * pixel_to_degrees\n",
    "        azimuth = np.degrees(np.arctan2(dx, dy))\n",
    "        # Normalize the azimuth to ensure it's within 0 to 360 degrees\n",
    "        azimuth = (azimuth + _rotation_az + 360) % 360\n",
    "        elevation = 90 - radius\n",
    "        positions.append((point['Timestamp'], point['Y'], point['X'], elevation, azimuth))\n",
    "    \n",
    "    df_positions = pd.DataFrame(positions, columns=['Timestamp', 'Y', 'X', 'Elevation', 'Azimuth'])\n",
    "    return df_positions\n",
    "\n",
    "def main(filename):\n",
    "    observed_positions = process_observed_data(filename)\n",
    "    if not observed_positions.empty:\n",
    "        print(observed_positions)\n",
    "        observed_positions.to_csv('processed_observed_data_an.csv', index=False)\n",
    "    else:\n",
    "        print(\"No valid observed data found.\")\n",
    "    return observed_positions\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    filename = 'white_pixel_coordinates_xor_an.csv'\n",
    "    observed_positions = main(filename)\n",
    "    observed_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199e4cf3-d064-46e9-85d1-73f7293578ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skyfield.api import load, wgs84, utc\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "\n",
    "def load_data():\n",
    "    stations_url = 'https://celestrak.org/NORAD/elements/gp.php?GROUP=starlink&FORMAT=tle'\n",
    "    satellites = load.tle_file(stations_url)\n",
    "    return satellites\n",
    "\n",
    "def set_observation_time(year, month, day, hour, minute, second):\n",
    "    ts = load.timescale()\n",
    "    return ts.utc(year, month, day, hour, minute, second)\n",
    "\n",
    "def process_observed_data(filename, start_time, merged_data_file):\n",
    "    data = pd.read_csv(filename, sep=',', header=None, names=['Timestamp', 'Y', 'X'])\n",
    "    data['Timestamp'] = pd.to_datetime(data['Timestamp'], utc=True)\n",
    "    interval_start_time = pd.to_datetime(start_time, utc=True)\n",
    "    interval_end_time = interval_start_time + pd.Timedelta(seconds=14)\n",
    "    filtered_data = data[(data['Timestamp'] >= interval_start_time) & (data['Timestamp'] < interval_end_time)]\n",
    "    if filtered_data.empty:\n",
    "        print(\"No data found.\")\n",
    "        return None\n",
    "\n",
    "    merged_data = pd.read_csv(merged_data_file, parse_dates=['Timestamp'])\n",
    "    merged_data['Timestamp'] = pd.to_datetime(merged_data['Timestamp'], utc=True)\n",
    "    merged_filtered_data = merged_data[(merged_data['Timestamp'] >= interval_start_time) & (merged_data['Timestamp'] < interval_end_time)]\n",
    "    \n",
    "    if merged_filtered_data.empty:\n",
    "        print(\"No matching data found in merged_data_file.\")\n",
    "        return None\n",
    "\n",
    "    if len(merged_filtered_data) < 3:\n",
    "        print(\"Not enough data points in merged_filtered_data.\")\n",
    "        return None\n",
    "\n",
    "    start_data = merged_filtered_data.iloc[0]\n",
    "    middle_data = merged_filtered_data.iloc[len(merged_filtered_data)//2]\n",
    "    end_data = merged_filtered_data.iloc[-2]\n",
    "    rotation = 0\n",
    "    positions = [\n",
    "        (start_data['Timestamp'], (90 - start_data['Elevation'], (start_data['Azimuth'] + rotation) % 360)),\n",
    "        (middle_data['Timestamp'], (90 - middle_data['Elevation'], (middle_data['Azimuth'] + rotation) % 360)),\n",
    "        (end_data['Timestamp'], (90 - end_data['Elevation'], (end_data['Azimuth'] + rotation) % 360))\n",
    "    ]\n",
    "    \n",
    "    return positions\n",
    "\n",
    "\n",
    "def calculate_positions_for_satellite(satellite, observer_location, start_time, interval_seconds, step_seconds):\n",
    "    ts = load.timescale()\n",
    "    positions = []\n",
    "    for second in range(0, interval_seconds + 1, step_seconds):\n",
    "        current_time = start_time + timedelta(seconds=second)\n",
    "        difference = satellite - observer_location\n",
    "        topocentric = difference.at(current_time)\n",
    "        alt, az, distance = topocentric.altaz()\n",
    "        if alt.degrees > 20:\n",
    "            positions.append((alt.degrees, az.degrees))\n",
    "    return positions\n",
    "\n",
    "def calculate_direction_vector(point1, point2):\n",
    "    \"\"\"Calculate the direction vector from point1 to point2.\"\"\"\n",
    "    alt_diff = point2[0] - point1[0]\n",
    "    az_diff = azimuth_difference(point2[1], point1[1])\n",
    "    magnitude = math.sqrt(alt_diff**2 + az_diff**2)\n",
    "    return (alt_diff / magnitude, az_diff / magnitude) if magnitude != 0 else (0, 0)\n",
    "\n",
    "def azimuth_difference(az1, az2):\n",
    "    \"\"\"Calculate the smallest difference between two azimuth angles.\"\"\"\n",
    "    diff = abs(az1 - az2) % 360\n",
    "    if diff > 180:\n",
    "        diff = 360 - diff\n",
    "    return diff\n",
    "\n",
    "def calculate_trajectory_distance(observed_positions, satellite_positions):\n",
    "    \"\"\"Calculate the distance measure between observed and satellite trajectories.\"\"\"\n",
    "    altitude_range = 90.0  # Maximum possible altitude difference\n",
    "    azimuth_range = 180.0  # Maximum possible azimuth difference\n",
    "    direction_range = 2.0  # Maximum possible direction difference \n",
    "    \n",
    "    distance = 0\n",
    "    for i in range(len(observed_positions)):\n",
    "        # Calculate distance between points\n",
    "        alt_deviation = abs(observed_positions[i][0] - satellite_positions[i][0]) / altitude_range\n",
    "        az_deviation = azimuth_difference(observed_positions[i][1], satellite_positions[i][1]) / azimuth_range\n",
    "        distance += alt_deviation + az_deviation\n",
    "    \n",
    "    # Calculate the overall direction vectors\n",
    "    obs_dir_vector = calculate_direction_vector(observed_positions[0], observed_positions[-1])\n",
    "    sat_dir_vector = calculate_direction_vector(satellite_positions[0], satellite_positions[len(observed_positions) - 1])\n",
    "    \n",
    "    # Calculate direction difference\n",
    "    direction_diff = math.sqrt((obs_dir_vector[0] - sat_dir_vector[0])**2 + (obs_dir_vector[1] - sat_dir_vector[1])**2) / direction_range\n",
    "    \n",
    "    # Add the direction difference to the distance measure\n",
    "    total_distance = distance + direction_diff\n",
    "    \n",
    "    return total_distance\n",
    "\n",
    "def find_matching_satellites(satellites, observer_location, observed_positions_with_timestamps):\n",
    "    best_match = None\n",
    "    closest_distance = float('inf')\n",
    "\n",
    "    ts = load.timescale()\n",
    "    \n",
    "    for satellite in satellites:\n",
    "        satellite_positions = []\n",
    "        valid_positions = True\n",
    "        \n",
    "        for observed_time, observed_data in observed_positions_with_timestamps:\n",
    "            # Calculate satellite position at the specific observed timestamp\n",
    "            difference = satellite - observer_location\n",
    "            topocentric = difference.at(ts.utc(observed_time.year, observed_time.month, observed_time.day, observed_time.hour, observed_time.minute, observed_time.second))\n",
    "            alt, az, _ = topocentric.altaz()\n",
    "            \n",
    "            if alt.degrees <= 20:\n",
    "                valid_positions = False\n",
    "                break\n",
    "            \n",
    "            satellite_positions.append((alt.degrees, az.degrees))\n",
    "        \n",
    "        if valid_positions:\n",
    "            total_distance = calculate_trajectory_distance(\n",
    "                [(90 - data[0], data[1]) for _, data in observed_positions_with_timestamps], \n",
    "                satellite_positions\n",
    "            )\n",
    "            \n",
    "            if total_distance < closest_distance:\n",
    "                closest_distance = total_distance\n",
    "                best_match = satellite.name\n",
    "    \n",
    "    return [best_match] if best_match else []\n",
    "\n",
    "def calculate_distance_for_best_match(satellite, observer_location, start_time, interval_seconds):\n",
    "    ts = load.timescale()\n",
    "    distances = []\n",
    "    for second in range(0, interval_seconds + 1):\n",
    "        current_time = start_time + timedelta(seconds=second)\n",
    "        difference = satellite - observer_location\n",
    "        topocentric = difference.at(current_time)\n",
    "        distance = topocentric.distance().km\n",
    "        distances.append(distance)\n",
    "    return distances\n",
    "\n",
    "def main(filename, year, month, day, hour, minute, second, merged_data_file, satellites):\n",
    "    initial_time = set_observation_time(year, month, day, hour, minute, second)\n",
    "    observer_location =wgs84.latlon(latitude_degrees=_lat, longitude_degrees= _lon, elevation_m=_alt)\n",
    "    interval_seconds = 15\n",
    "    observed_positions_with_timestamps = process_observed_data(filename, initial_time.utc_strftime('%Y-%m-%dT%H:%M:%SZ'), merged_data_file)\n",
    "    if observed_positions_with_timestamps is None:\n",
    "        return [], [], []\n",
    "\n",
    "    matching_satellites = find_matching_satellites(satellites, observer_location, observed_positions_with_timestamps)\n",
    "    if not matching_satellites:\n",
    "        return observed_positions_with_timestamps, [], []\n",
    "\n",
    "    best_match_satellite = next(sat for sat in satellites if sat.name == matching_satellites[0])\n",
    "    distances = calculate_distance_for_best_match(best_match_satellite, observer_location, initial_time, 14)\n",
    "    \n",
    "    return observed_positions_with_timestamps, matching_satellites, distances\n",
    "\n",
    "def process_intervals(filename, start_year, start_month, start_day, start_hour, start_minute, start_second, end_year, end_month, end_day, end_hour, end_minute, end_second, merged_data_file, satellites):\n",
    "    results = []\n",
    "    \n",
    "    start_time = datetime(start_year, start_month, start_day, start_hour, start_minute, start_second, tzinfo=utc)\n",
    "    end_time = datetime(end_year, end_month, end_day, end_hour, end_minute, end_second, tzinfo=utc)\n",
    "    current_time = start_time\n",
    "    \n",
    "    while current_time <= end_time:\n",
    "        print(f\"Processing data for {current_time}\")\n",
    "        observed_positions_with_timestamps, matching_satellites, distances = main(filename, current_time.year, current_time.month, current_time.day, current_time.hour, current_time.minute, current_time.second, merged_data_file, satellites)\n",
    "        if matching_satellites:\n",
    "            for second in range(15):\n",
    "                if second < len(distances):\n",
    "                    results.append({\n",
    "                        'Timestamp': current_time + timedelta(seconds=second),\n",
    "                        'Connected_Satellite': matching_satellites[0],\n",
    "                        'Distance': distances[second]\n",
    "                    })\n",
    "        current_time += timedelta(seconds=15)\n",
    "    \n",
    "    result_df = pd.DataFrame(results)\n",
    "    return result_df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    filename = 'white_pixel_coordinates_xor_an.csv'\n",
    "    merged_data_file = 'processed_observed_data_an.csv'\n",
    "    \n",
    "    # Load satellite data once\n",
    "    satellites = load_data()\n",
    "    \n",
    "    # Process intervals for the specified range of timestamps\n",
    "    result_df = process_intervals(filename, _first_year, _first_month, _first_day,  _first_hour, _first_minute,_first_second, _last_year, _last_month, _last_day,  _last_hour, _last_minute,_last_second, merged_data_file, satellites)\n",
    "\n",
    "    # Load the data from both CSV files\n",
    "    merged_data_df = pd.read_csv(merged_data_file, parse_dates=['Timestamp'])\n",
    "\n",
    "    # Load the existing matched_satellite_data.csv if it exists\n",
    "    if os.path.exists('matched_satellite_data_an.csv'):\n",
    "        existing_df = pd.read_csv('matched_satellite_data_an.csv', parse_dates=['Timestamp'])\n",
    "    else:\n",
    "        existing_df = pd.DataFrame()\n",
    "\n",
    "    # Merge the dataframes on Timestamp column\n",
    "    merged_df = pd.merge(merged_data_df, result_df, on='Timestamp', how='inner')\n",
    "\n",
    "    # Append the new data to the existing data\n",
    "    updated_df = pd.concat([existing_df, merged_df]).drop_duplicates(subset=['Timestamp'], keep='last')\n",
    "\n",
    "    # Save the updated dataframe to the CSV file\n",
    "    updated_df.to_csv('matched_satellite_data_an.csv', index=False)\n",
    "\n",
    "    print(\"Updated data saved to 'matched_satellite_data.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f134c9ce-fe5a-4303-87dd-aa5ad4aece84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import timedelta\n",
    "import math\n",
    "from skyfield.api import load, wgs84, EarthSatellite\n",
    "import json\n",
    "import os\n",
    "\n",
    "def load_data():\n",
    "    stations_url = 'gp.php'\n",
    "    satellites = load.tle_file(stations_url)\n",
    "    print('Loaded', len(satellites), 'satellites')\n",
    "    return satellites\n",
    "\n",
    "def set_observation_time(year, month, day, hour, minute, second):\n",
    "    ts = load.timescale()\n",
    "    return ts.utc(year, month, day, hour, minute, second)\n",
    "\n",
    "def calculate_satellite_positions(satellites, observer_location, observation_time):\n",
    "    locations = []\n",
    "    sats = []\n",
    "    min_elevation = 20\n",
    "    for satellite in satellites:\n",
    "        difference = satellite - observer_location\n",
    "        topocentric = difference.at(observation_time)\n",
    "        alt, az, distance = topocentric.altaz()\n",
    "        if alt.degrees > min_elevation:\n",
    "            loc = [(90 - alt.degrees, np.radians(az.degrees))]\n",
    "            locations.append(loc)\n",
    "            sats.append((satellite, alt, az, distance))\n",
    "    return locations, sats\n",
    "\n",
    "def rotate_points(x, y, angle):\n",
    "    x_rot = x * np.cos(angle) - y * np.sin(angle)\n",
    "    y_rot = x * np.sin(angle) + y * np.cos(angle)\n",
    "    return x_rot, y_rot\n",
    "\n",
    "def find_fov_sats(timestamps, satellites, observer_location, tilt_deg, rotation_deg):\n",
    "    fov_data = []\n",
    "\n",
    "    base_radius = 60\n",
    "    center_shift = tilt_deg\n",
    "    x_radius = base_radius\n",
    "    y_radius = math.sqrt(base_radius**2 - tilt_deg**2)\n",
    "\n",
    "    for timestamp in timestamps:\n",
    "        observation_time = set_observation_time(timestamp.year, timestamp.month, timestamp.day, timestamp.hour, timestamp.minute, timestamp.second)\n",
    "        locations, sats = calculate_satellite_positions(satellites, observer_location, observation_time)\n",
    "        \n",
    "        fov_sats = []\n",
    "        for loc, sat in zip(locations, sats):\n",
    "            loc = np.array(loc)\n",
    "            r = loc[:, 0]\n",
    "            angle = loc[:, 1]\n",
    "            inside = False\n",
    "            for r_i, angle_i in zip(r, angle):\n",
    "                x_point = r_i * np.cos(angle_i)\n",
    "                y_point = r_i * np.sin(angle_i)\n",
    "                x_point_rot, y_point_rot = rotate_points(x_point, y_point, -np.deg2rad(rotation_deg))\n",
    "                x_point_rot -= center_shift\n",
    "                if (x_point_rot**2 / x_radius**2) + (y_point_rot**2 / y_radius**2) <= 1:\n",
    "                    inside = True\n",
    "                    break\n",
    "            if inside:\n",
    "                fov_sats.append({\n",
    "                    'Name': sat[0].name,\n",
    "                    'Azimuth': sat[2].degrees,\n",
    "                    'Elevation': sat[1].degrees,\n",
    "                    'Distance': sat[3].km,\n",
    "                    'Inclination': sat[0].model.inclo * 180.0 / np.pi\n",
    "                })\n",
    "        fov_data.append({\n",
    "            'Timestamp': timestamp.isoformat(),\n",
    "            'Satellites': fov_sats\n",
    "        })\n",
    "\n",
    "    return fov_data\n",
    "\n",
    "def save_fov_data(fov_data, filename='fov_data_an.json'):\n",
    "    with open(filename, 'w') as file:\n",
    "        json.dump(fov_data, file)\n",
    "\n",
    "def load_fov_data(filename='fov_data_an.json'):\n",
    "    if os.path.exists(filename):\n",
    "        with open(filename, 'r') as file:\n",
    "            fov_data = json.load(file)\n",
    "        print('Loaded fov_data from file')\n",
    "        return fov_data\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def calculate_cdf(data):\n",
    "    sorted_data = np.sort(data)\n",
    "    cdf = np.arange(1, len(sorted_data) + 1) / len(sorted_data)\n",
    "    return sorted_data, cdf\n",
    "\n",
    "def plot_cdfs(fov_data, matched_data):\n",
    "    azimuths = []\n",
    "    elevations = []\n",
    "    distances = []\n",
    "    inclinations = []\n",
    "\n",
    "    for entry in fov_data:\n",
    "        for sat in entry['Satellites']:\n",
    "            azimuths.append(sat['Azimuth'])\n",
    "            elevations.append(sat['Elevation'])\n",
    "            distances.append(sat['Distance'])\n",
    "            inclinations.append(sat['Inclination'])\n",
    "\n",
    "    azimuth_sorted, azimuth_cdf = calculate_cdf(azimuths)\n",
    "    elevation_sorted, elevation_cdf = calculate_cdf(elevations)\n",
    "    distance_sorted, distance_cdf = calculate_cdf(distances)\n",
    "    inclination_sorted, inclination_cdf = calculate_cdf(inclinations)\n",
    "\n",
    "    # Plot for available satellites\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    ax.plot(distance_sorted, distance_cdf, linestyle='-', color='blue', label='Available Satellites Distance')\n",
    "    ax.set_title('CDF of Distance', fontsize=24)\n",
    "    ax.set_xlabel('Distance (km)', fontsize=24)\n",
    "    ax.set_ylabel('CDF', fontsize=24)\n",
    "    ax.grid(True)\n",
    "    ax.legend(fontsize=16)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=24)\n",
    "    matched_distances = matched_data['Distance'].dropna()\n",
    "    matched_distance_sorted, matched_distance_cdf = calculate_cdf(matched_distances)\n",
    "    ax.plot(matched_distance_sorted, matched_distance_cdf, linestyle='-', color='red', label='Matched Satellites Distance')\n",
    "    ax.legend(fontsize=18)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('CDF_Distance.png')\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    ax.plot(elevation_sorted, elevation_cdf, linestyle='-', color='blue', label='Available Satellites Elevation')\n",
    "    ax.set_title('CDF of Elevation', fontsize=24)\n",
    "    ax.set_xlabel('Elevation (degrees)', fontsize=24)\n",
    "    ax.set_ylabel('CDF', fontsize=24)\n",
    "    ax.grid(True)\n",
    "    ax.legend(fontsize=16)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=24)\n",
    "    matched_elevations = matched_data['Elevation'].dropna()\n",
    "    matched_elevation_sorted, matched_elevation_cdf = calculate_cdf(matched_elevations)\n",
    "    ax.plot(matched_elevation_sorted, matched_elevation_cdf, linestyle='-', color='red', label='Matched Satellites Elevation')\n",
    "    ax.legend(fontsize=18)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('CDF_Elevation.png')\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    ax.plot(azimuth_sorted, azimuth_cdf, linestyle='-', color='blue', label='Available Satellites Azimuth')\n",
    "    ax.set_title('CDF of Azimuth', fontsize=24)\n",
    "    ax.set_xlabel('Azimuth (degrees)', fontsize=24)\n",
    "    ax.set_ylabel('CDF', fontsize=24)\n",
    "    ax.grid(True)\n",
    "    ax.legend(fontsize=16)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=24)\n",
    "    matched_azimuths = matched_data['Azimuth'].dropna()\n",
    "    matched_azimuths = (matched_azimuths)%360\n",
    "    matched_azimuth_sorted, matched_azimuth_cdf = calculate_cdf(matched_azimuths)\n",
    "    ax.plot(matched_azimuth_sorted, matched_azimuth_cdf, linestyle='-', color='red', label='Matched Satellites Azimuth')\n",
    "    ax.legend(fontsize=18)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('CDF_Azimuth.png')\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    ax.plot(inclination_sorted, inclination_cdf, linestyle='-', color='blue', label='Available Satellites Inclination')\n",
    "    ax.set_title('CDF of Inclination', fontsize=24)\n",
    "    ax.set_xlabel('Inclination (degrees)', fontsize=24)\n",
    "    ax.set_ylabel('CDF', fontsize=24)\n",
    "    ax.grid(True)\n",
    "    ax.legend(fontsize=16)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=24)\n",
    "    matched_inclinations = matched_data['Inclination'].dropna()\n",
    "    matched_inclination_sorted, matched_inclination_cdf = calculate_cdf(matched_inclinations)\n",
    "    ax.plot(matched_inclination_sorted, matched_inclination_cdf, linestyle='-', color='red', label='Matched Satellites Inclination')\n",
    "    ax.legend(fontsize=18)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('CDF_Inclination.png')\n",
    "\n",
    "# Load the data\n",
    "file_path = 'matched_satellite_data_an.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "# Convert Timestamp to datetime\n",
    "data['Timestamp'] = pd.to_datetime(data['Timestamp'])\n",
    "# data = data.loc[:28]\n",
    "# Filter the timestamps with the required seconds\n",
    "filtered_data = data[data['Timestamp'].dt.second.isin([12, 27, 42, 57])]\n",
    "\n",
    "# Load satellite data\n",
    "satellites = load_data()\n",
    "\n",
    "# Observer location (hardcoded based on previous input)\n",
    "observer_location = wgs84.latlon(latitude_degrees=_lat, longitude_degrees= _lon, elevation_m=_alt)\n",
    "\n",
    "# Load fov_data if it exists, otherwise calculate it\n",
    "fov_data = load_fov_data()\n",
    "\n",
    "if fov_data is None:\n",
    "    # Find satellites in the FOV for the filtered timestamps\n",
    "    fov_data = find_fov_sats(filtered_data['Timestamp'].unique(), satellites, observer_location, _tilt, _rotation_az)\n",
    "    save_fov_data(fov_data)\n",
    "\n",
    "# Load TLE data for inclination\n",
    "satellites = load.tle_file('gp.php')\n",
    "inclinations = {sat.name: sat.model.inclo * 180.0 / np.pi for sat in satellites}\n",
    "\n",
    "# Add inclination data to the matched dataframe\n",
    "data['Inclination'] = data['Connected_Satellite'].map(inclinations)\n",
    "\n",
    "# Plot CDFs\n",
    "plot_cdfs(fov_data, data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460f592f-149e-461a-989b-39cf5360d4c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
