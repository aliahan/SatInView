{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "809583cb-b5df-41ff-832c-1af7c2940e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Timestamp   Y   X  Elevation     Azimuth\n",
      "0    2024-07-17 18:07:57+00:00  63  20  32.202407  290.340463\n",
      "1    2024-07-17 18:07:58+00:00  63  20  32.202407  290.340463\n",
      "2    2024-07-17 18:07:59+00:00  63  20  32.202407  290.340463\n",
      "3    2024-07-17 18:08:00+00:00  62  21  33.855621  289.563476\n",
      "4    2024-07-17 18:08:01+00:00  62  21  33.855621  289.563476\n",
      "...                        ...  ..  ..        ...         ...\n",
      "6995 2024-07-17 20:12:51+00:00  70  89  44.592287   50.106875\n",
      "6996 2024-07-17 20:12:52+00:00  70  89  44.592287   50.106875\n",
      "6997 2024-07-17 20:12:53+00:00  69  89  45.408854   51.379031\n",
      "6998 2024-07-17 20:12:54+00:00  69  89  45.408854   51.379031\n",
      "6999 2024-07-17 20:12:55+00:00  68  89  46.202625   52.697970\n",
      "\n",
      "[7000 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def process_observed_data(filename):\n",
    "    data = pd.read_csv(filename, sep=',', header=None, names=['Timestamp', 'Y', 'X'])\n",
    "    data['Timestamp'] = pd.to_datetime(data['Timestamp'], utc=True)\n",
    "    \n",
    "    observer_x, observer_y = 62, 62 - (18.8 / (80/62))  # Assume this is the observer's pixel location\n",
    "    pixel_to_degrees = (80/62)  # Conversion factor from pixel to degrees\n",
    "    \n",
    "    positions = []\n",
    "    for index, point in data.iterrows():\n",
    "        dx, dy = point['X'] - observer_x, point['Y'] - observer_y\n",
    "        radius = np.sqrt(dx**2 + dy**2) * pixel_to_degrees\n",
    "        azimuth = np.degrees(np.arctan2(dx, dy))\n",
    "        # Normalize the azimuth to ensure it's within 0 to 360 degrees\n",
    "        azimuth = (azimuth + 360) % 360\n",
    "        elevation = 90 - radius\n",
    "        positions.append((point['Timestamp'], point['Y'], point['X'], elevation, azimuth))\n",
    "    \n",
    "    df_positions = pd.DataFrame(positions, columns=['Timestamp', 'Y', 'X', 'Elevation', 'Azimuth'])\n",
    "    return df_positions\n",
    "\n",
    "def main(filename):\n",
    "    observed_positions = process_observed_data(filename)\n",
    "    if not observed_positions.empty:\n",
    "        print(observed_positions)\n",
    "        observed_positions.to_csv('processed_observed_data.csv', index=False)\n",
    "    else:\n",
    "        print(\"No valid observed data found.\")\n",
    "    return observed_positions\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    filename = 'white_pixel_coordinates_xor.csv'\n",
    "    observed_positions = main(filename)\n",
    "    observed_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199e4cf3-d064-46e9-85d1-73f7293578ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data for 2024-07-17 18:07:57+00:00\n",
      "Processing data for 2024-07-17 18:08:12+00:00\n",
      "Processing data for 2024-07-17 18:08:27+00:00\n",
      "Processing data for 2024-07-17 18:08:42+00:00\n",
      "Processing data for 2024-07-17 18:08:57+00:00\n",
      "Processing data for 2024-07-17 18:09:12+00:00\n",
      "Processing data for 2024-07-17 18:09:27+00:00\n",
      "Processing data for 2024-07-17 18:09:42+00:00\n",
      "Processing data for 2024-07-17 18:09:57+00:00\n",
      "Processing data for 2024-07-17 18:10:12+00:00\n",
      "Processing data for 2024-07-17 18:10:27+00:00\n",
      "Processing data for 2024-07-17 18:10:42+00:00\n",
      "Processing data for 2024-07-17 18:10:57+00:00\n",
      "Processing data for 2024-07-17 18:11:12+00:00\n",
      "Processing data for 2024-07-17 18:11:27+00:00\n",
      "Processing data for 2024-07-17 18:11:42+00:00\n",
      "Processing data for 2024-07-17 18:11:57+00:00\n",
      "Processing data for 2024-07-17 18:12:12+00:00\n",
      "Processing data for 2024-07-17 18:12:27+00:00\n",
      "Processing data for 2024-07-17 18:12:42+00:00\n",
      "Processing data for 2024-07-17 18:12:57+00:00\n",
      "Processing data for 2024-07-17 18:13:12+00:00\n",
      "Processing data for 2024-07-17 18:13:27+00:00\n",
      "Processing data for 2024-07-17 18:13:42+00:00\n",
      "Processing data for 2024-07-17 18:13:57+00:00\n",
      "Processing data for 2024-07-17 18:14:12+00:00\n",
      "Processing data for 2024-07-17 18:14:27+00:00\n",
      "Processing data for 2024-07-17 18:14:42+00:00\n",
      "Processing data for 2024-07-17 18:14:57+00:00\n",
      "Processing data for 2024-07-17 18:15:12+00:00\n",
      "Processing data for 2024-07-17 18:15:27+00:00\n",
      "Processing data for 2024-07-17 18:15:42+00:00\n",
      "Processing data for 2024-07-17 18:15:57+00:00\n",
      "Processing data for 2024-07-17 18:16:12+00:00\n",
      "Processing data for 2024-07-17 18:16:27+00:00\n",
      "Processing data for 2024-07-17 18:16:42+00:00\n",
      "Processing data for 2024-07-17 18:16:57+00:00\n",
      "Processing data for 2024-07-17 18:17:12+00:00\n",
      "Processing data for 2024-07-17 18:17:27+00:00\n",
      "Processing data for 2024-07-17 18:17:42+00:00\n",
      "Processing data for 2024-07-17 18:17:57+00:00\n",
      "Processing data for 2024-07-17 18:18:12+00:00\n",
      "Processing data for 2024-07-17 18:18:27+00:00\n",
      "Processing data for 2024-07-17 18:18:42+00:00\n",
      "Processing data for 2024-07-17 18:18:57+00:00\n",
      "Processing data for 2024-07-17 18:19:12+00:00\n",
      "Processing data for 2024-07-17 18:19:27+00:00\n",
      "Processing data for 2024-07-17 18:19:42+00:00\n",
      "Processing data for 2024-07-17 18:19:57+00:00\n",
      "Processing data for 2024-07-17 18:20:12+00:00\n",
      "Processing data for 2024-07-17 18:20:27+00:00\n",
      "Processing data for 2024-07-17 18:20:42+00:00\n",
      "Processing data for 2024-07-17 18:20:57+00:00\n",
      "Processing data for 2024-07-17 18:21:12+00:00\n",
      "Processing data for 2024-07-17 18:21:27+00:00\n",
      "Processing data for 2024-07-17 18:21:42+00:00\n",
      "Processing data for 2024-07-17 18:21:57+00:00\n",
      "Processing data for 2024-07-17 18:22:12+00:00\n",
      "Processing data for 2024-07-17 18:22:27+00:00\n",
      "Processing data for 2024-07-17 18:22:42+00:00\n",
      "Processing data for 2024-07-17 18:22:57+00:00\n",
      "Processing data for 2024-07-17 18:23:12+00:00\n",
      "Processing data for 2024-07-17 18:23:27+00:00\n",
      "Processing data for 2024-07-17 18:23:42+00:00\n",
      "Processing data for 2024-07-17 18:23:57+00:00\n",
      "Processing data for 2024-07-17 18:24:12+00:00\n",
      "Processing data for 2024-07-17 18:24:27+00:00\n",
      "Processing data for 2024-07-17 18:24:42+00:00\n",
      "Processing data for 2024-07-17 18:24:57+00:00\n",
      "Processing data for 2024-07-17 18:25:12+00:00\n",
      "Processing data for 2024-07-17 18:25:27+00:00\n",
      "Processing data for 2024-07-17 18:25:42+00:00\n",
      "Processing data for 2024-07-17 18:25:57+00:00\n",
      "Processing data for 2024-07-17 18:26:12+00:00\n",
      "Processing data for 2024-07-17 18:26:27+00:00\n",
      "Processing data for 2024-07-17 18:26:42+00:00\n",
      "Processing data for 2024-07-17 18:26:57+00:00\n",
      "Processing data for 2024-07-17 18:27:12+00:00\n",
      "Processing data for 2024-07-17 18:27:27+00:00\n",
      "Processing data for 2024-07-17 18:27:42+00:00\n",
      "Processing data for 2024-07-17 18:27:57+00:00\n",
      "Processing data for 2024-07-17 18:28:12+00:00\n",
      "Processing data for 2024-07-17 18:28:27+00:00\n",
      "Processing data for 2024-07-17 18:28:42+00:00\n",
      "Processing data for 2024-07-17 18:28:57+00:00\n",
      "Processing data for 2024-07-17 18:29:12+00:00\n",
      "Processing data for 2024-07-17 18:29:27+00:00\n",
      "Processing data for 2024-07-17 18:29:42+00:00\n",
      "Processing data for 2024-07-17 18:29:57+00:00\n",
      "Processing data for 2024-07-17 18:30:12+00:00\n",
      "Processing data for 2024-07-17 18:30:27+00:00\n",
      "Processing data for 2024-07-17 18:30:42+00:00\n",
      "Processing data for 2024-07-17 18:30:57+00:00\n",
      "Processing data for 2024-07-17 18:31:12+00:00\n",
      "Processing data for 2024-07-17 18:31:27+00:00\n",
      "Processing data for 2024-07-17 18:31:42+00:00\n",
      "Processing data for 2024-07-17 18:31:57+00:00\n",
      "Processing data for 2024-07-17 18:32:12+00:00\n",
      "Processing data for 2024-07-17 18:32:27+00:00\n",
      "Processing data for 2024-07-17 18:32:42+00:00\n",
      "Processing data for 2024-07-17 18:32:57+00:00\n",
      "Processing data for 2024-07-17 18:33:12+00:00\n",
      "Processing data for 2024-07-17 18:33:27+00:00\n",
      "Processing data for 2024-07-17 18:33:42+00:00\n",
      "Processing data for 2024-07-17 18:33:57+00:00\n",
      "Processing data for 2024-07-17 18:34:12+00:00\n",
      "Processing data for 2024-07-17 18:34:27+00:00\n",
      "Processing data for 2024-07-17 18:34:42+00:00\n",
      "Processing data for 2024-07-17 18:34:57+00:00\n",
      "Processing data for 2024-07-17 18:35:12+00:00\n",
      "Processing data for 2024-07-17 18:35:27+00:00\n",
      "Processing data for 2024-07-17 18:35:42+00:00\n",
      "Processing data for 2024-07-17 18:35:57+00:00\n",
      "Processing data for 2024-07-17 18:36:12+00:00\n",
      "Processing data for 2024-07-17 18:36:27+00:00\n",
      "Processing data for 2024-07-17 18:36:42+00:00\n",
      "Processing data for 2024-07-17 18:36:57+00:00\n",
      "Processing data for 2024-07-17 18:37:12+00:00\n",
      "Processing data for 2024-07-17 18:37:27+00:00\n",
      "Processing data for 2024-07-17 18:37:42+00:00\n",
      "Processing data for 2024-07-17 18:37:57+00:00\n",
      "Processing data for 2024-07-17 18:38:12+00:00\n",
      "Processing data for 2024-07-17 18:38:27+00:00\n",
      "Processing data for 2024-07-17 18:38:42+00:00\n",
      "Processing data for 2024-07-17 18:38:57+00:00\n",
      "Processing data for 2024-07-17 18:39:12+00:00\n",
      "Processing data for 2024-07-17 18:39:27+00:00\n",
      "Processing data for 2024-07-17 18:39:42+00:00\n",
      "Processing data for 2024-07-17 18:39:57+00:00\n",
      "Processing data for 2024-07-17 18:40:12+00:00\n",
      "Processing data for 2024-07-17 18:40:27+00:00\n",
      "Processing data for 2024-07-17 18:40:42+00:00\n",
      "Processing data for 2024-07-17 18:40:57+00:00\n",
      "Processing data for 2024-07-17 18:41:12+00:00\n",
      "Processing data for 2024-07-17 18:41:27+00:00\n",
      "Processing data for 2024-07-17 18:41:42+00:00\n",
      "Processing data for 2024-07-17 18:41:57+00:00\n",
      "Processing data for 2024-07-17 18:42:12+00:00\n",
      "Processing data for 2024-07-17 18:42:27+00:00\n",
      "Processing data for 2024-07-17 18:42:42+00:00\n",
      "Processing data for 2024-07-17 18:42:57+00:00\n",
      "Processing data for 2024-07-17 18:43:12+00:00\n",
      "Processing data for 2024-07-17 18:43:27+00:00\n",
      "Processing data for 2024-07-17 18:43:42+00:00\n",
      "Processing data for 2024-07-17 18:43:57+00:00\n",
      "Processing data for 2024-07-17 18:44:12+00:00\n",
      "Processing data for 2024-07-17 18:44:27+00:00\n",
      "Processing data for 2024-07-17 18:44:42+00:00\n",
      "Processing data for 2024-07-17 18:44:57+00:00\n",
      "Processing data for 2024-07-17 18:45:12+00:00\n",
      "Processing data for 2024-07-17 18:45:27+00:00\n",
      "Processing data for 2024-07-17 18:45:42+00:00\n",
      "Processing data for 2024-07-17 18:45:57+00:00\n",
      "Processing data for 2024-07-17 18:46:12+00:00\n",
      "Processing data for 2024-07-17 18:46:27+00:00\n",
      "Processing data for 2024-07-17 18:46:42+00:00\n",
      "Processing data for 2024-07-17 18:46:57+00:00\n",
      "Processing data for 2024-07-17 18:47:12+00:00\n",
      "Processing data for 2024-07-17 18:47:27+00:00\n",
      "Processing data for 2024-07-17 18:47:42+00:00\n",
      "Processing data for 2024-07-17 18:47:57+00:00\n",
      "Processing data for 2024-07-17 18:48:12+00:00\n",
      "Processing data for 2024-07-17 18:48:27+00:00\n",
      "Processing data for 2024-07-17 18:48:42+00:00\n",
      "Processing data for 2024-07-17 18:48:57+00:00\n",
      "Processing data for 2024-07-17 18:49:12+00:00\n",
      "Processing data for 2024-07-17 18:49:27+00:00\n",
      "Processing data for 2024-07-17 18:49:42+00:00\n",
      "Processing data for 2024-07-17 18:49:57+00:00\n",
      "Processing data for 2024-07-17 18:50:12+00:00\n",
      "Processing data for 2024-07-17 18:50:27+00:00\n",
      "Processing data for 2024-07-17 18:50:42+00:00\n",
      "Processing data for 2024-07-17 18:50:57+00:00\n",
      "Processing data for 2024-07-17 18:51:12+00:00\n",
      "Processing data for 2024-07-17 18:51:27+00:00\n",
      "Processing data for 2024-07-17 18:51:42+00:00\n",
      "Processing data for 2024-07-17 18:51:57+00:00\n",
      "Processing data for 2024-07-17 18:52:12+00:00\n",
      "Processing data for 2024-07-17 18:52:27+00:00\n",
      "Processing data for 2024-07-17 18:52:42+00:00\n",
      "Processing data for 2024-07-17 18:52:57+00:00\n",
      "Processing data for 2024-07-17 18:53:12+00:00\n",
      "Processing data for 2024-07-17 18:53:27+00:00\n",
      "Processing data for 2024-07-17 18:53:42+00:00\n",
      "Processing data for 2024-07-17 18:53:57+00:00\n",
      "Processing data for 2024-07-17 18:54:12+00:00\n",
      "Processing data for 2024-07-17 18:54:27+00:00\n",
      "Processing data for 2024-07-17 18:54:42+00:00\n",
      "Processing data for 2024-07-17 18:54:57+00:00\n",
      "Processing data for 2024-07-17 18:55:12+00:00\n",
      "Processing data for 2024-07-17 18:55:27+00:00\n",
      "Processing data for 2024-07-17 18:55:42+00:00\n",
      "Processing data for 2024-07-17 18:55:57+00:00\n",
      "Processing data for 2024-07-17 18:56:12+00:00\n",
      "Processing data for 2024-07-17 18:56:27+00:00\n",
      "Processing data for 2024-07-17 18:56:42+00:00\n",
      "Processing data for 2024-07-17 18:56:57+00:00\n",
      "Processing data for 2024-07-17 18:57:12+00:00\n",
      "Processing data for 2024-07-17 18:57:27+00:00\n",
      "Processing data for 2024-07-17 18:57:42+00:00\n",
      "Processing data for 2024-07-17 18:57:57+00:00\n",
      "Processing data for 2024-07-17 18:58:12+00:00\n",
      "Processing data for 2024-07-17 18:58:27+00:00\n",
      "Processing data for 2024-07-17 18:58:42+00:00\n",
      "Processing data for 2024-07-17 18:58:57+00:00\n",
      "Processing data for 2024-07-17 18:59:12+00:00\n",
      "Processing data for 2024-07-17 18:59:27+00:00\n",
      "Processing data for 2024-07-17 18:59:42+00:00\n",
      "Processing data for 2024-07-17 18:59:57+00:00\n",
      "Processing data for 2024-07-17 19:00:12+00:00\n",
      "Processing data for 2024-07-17 19:00:27+00:00\n",
      "Processing data for 2024-07-17 19:00:42+00:00\n",
      "Processing data for 2024-07-17 19:00:57+00:00\n",
      "Processing data for 2024-07-17 19:01:12+00:00\n",
      "Processing data for 2024-07-17 19:01:27+00:00\n",
      "Processing data for 2024-07-17 19:01:42+00:00\n",
      "Processing data for 2024-07-17 19:01:57+00:00\n",
      "Processing data for 2024-07-17 19:02:12+00:00\n",
      "Processing data for 2024-07-17 19:02:27+00:00\n",
      "Processing data for 2024-07-17 19:02:42+00:00\n",
      "Processing data for 2024-07-17 19:02:57+00:00\n",
      "Processing data for 2024-07-17 19:03:12+00:00\n",
      "Processing data for 2024-07-17 19:03:27+00:00\n",
      "Processing data for 2024-07-17 19:03:42+00:00\n",
      "Processing data for 2024-07-17 19:03:57+00:00\n",
      "Processing data for 2024-07-17 19:04:12+00:00\n",
      "Processing data for 2024-07-17 19:04:27+00:00\n",
      "Processing data for 2024-07-17 19:04:42+00:00\n",
      "Processing data for 2024-07-17 19:04:57+00:00\n",
      "Processing data for 2024-07-17 19:05:12+00:00\n",
      "Processing data for 2024-07-17 19:05:27+00:00\n",
      "Processing data for 2024-07-17 19:05:42+00:00\n",
      "Processing data for 2024-07-17 19:05:57+00:00\n",
      "Processing data for 2024-07-17 19:06:12+00:00\n",
      "Processing data for 2024-07-17 19:06:27+00:00\n",
      "Processing data for 2024-07-17 19:06:42+00:00\n",
      "Processing data for 2024-07-17 19:06:57+00:00\n",
      "Processing data for 2024-07-17 19:07:12+00:00\n",
      "Processing data for 2024-07-17 19:07:27+00:00\n",
      "Processing data for 2024-07-17 19:07:42+00:00\n",
      "Processing data for 2024-07-17 19:07:57+00:00\n",
      "Processing data for 2024-07-17 19:08:12+00:00\n",
      "Processing data for 2024-07-17 19:08:27+00:00\n",
      "Processing data for 2024-07-17 19:08:42+00:00\n",
      "Processing data for 2024-07-17 19:08:57+00:00\n",
      "Processing data for 2024-07-17 19:09:12+00:00\n",
      "Processing data for 2024-07-17 19:09:27+00:00\n",
      "Processing data for 2024-07-17 19:09:42+00:00\n",
      "Processing data for 2024-07-17 19:09:57+00:00\n",
      "Processing data for 2024-07-17 19:10:12+00:00\n",
      "Processing data for 2024-07-17 19:10:27+00:00\n",
      "Processing data for 2024-07-17 19:10:42+00:00\n",
      "Processing data for 2024-07-17 19:10:57+00:00\n",
      "Processing data for 2024-07-17 19:11:12+00:00\n",
      "Processing data for 2024-07-17 19:11:27+00:00\n",
      "Processing data for 2024-07-17 19:11:42+00:00\n",
      "Processing data for 2024-07-17 19:11:57+00:00\n",
      "Processing data for 2024-07-17 19:12:12+00:00\n",
      "Processing data for 2024-07-17 19:12:27+00:00\n",
      "Processing data for 2024-07-17 19:12:42+00:00\n",
      "Processing data for 2024-07-17 19:12:57+00:00\n",
      "Processing data for 2024-07-17 19:13:12+00:00\n",
      "Processing data for 2024-07-17 19:13:27+00:00\n",
      "Processing data for 2024-07-17 19:13:42+00:00\n",
      "Processing data for 2024-07-17 19:13:57+00:00\n",
      "Processing data for 2024-07-17 19:14:12+00:00\n",
      "Processing data for 2024-07-17 19:14:27+00:00\n",
      "Processing data for 2024-07-17 19:14:42+00:00\n",
      "Processing data for 2024-07-17 19:14:57+00:00\n",
      "Processing data for 2024-07-17 19:15:12+00:00\n",
      "Processing data for 2024-07-17 19:15:27+00:00\n",
      "Processing data for 2024-07-17 19:15:42+00:00\n",
      "Processing data for 2024-07-17 19:15:57+00:00\n",
      "Processing data for 2024-07-17 19:16:12+00:00\n",
      "Processing data for 2024-07-17 19:16:27+00:00\n",
      "Processing data for 2024-07-17 19:16:42+00:00\n",
      "Processing data for 2024-07-17 19:16:57+00:00\n",
      "Processing data for 2024-07-17 19:17:12+00:00\n",
      "Processing data for 2024-07-17 19:17:27+00:00\n",
      "Processing data for 2024-07-17 19:17:42+00:00\n",
      "Processing data for 2024-07-17 19:17:57+00:00\n",
      "Processing data for 2024-07-17 19:18:12+00:00\n",
      "Processing data for 2024-07-17 19:18:27+00:00\n",
      "Processing data for 2024-07-17 19:18:42+00:00\n",
      "Processing data for 2024-07-17 19:18:57+00:00\n",
      "Processing data for 2024-07-17 19:19:12+00:00\n",
      "Processing data for 2024-07-17 19:19:27+00:00\n",
      "Processing data for 2024-07-17 19:19:42+00:00\n",
      "Processing data for 2024-07-17 19:19:57+00:00\n",
      "Processing data for 2024-07-17 19:20:12+00:00\n",
      "Processing data for 2024-07-17 19:20:27+00:00\n",
      "Processing data for 2024-07-17 19:20:42+00:00\n",
      "Processing data for 2024-07-17 19:20:57+00:00\n",
      "Processing data for 2024-07-17 19:21:12+00:00\n",
      "Processing data for 2024-07-17 19:21:27+00:00\n",
      "Processing data for 2024-07-17 19:21:42+00:00\n",
      "Processing data for 2024-07-17 19:21:57+00:00\n",
      "Processing data for 2024-07-17 19:22:12+00:00\n",
      "Processing data for 2024-07-17 19:22:27+00:00\n",
      "Processing data for 2024-07-17 19:22:42+00:00\n",
      "Processing data for 2024-07-17 19:22:57+00:00\n",
      "Processing data for 2024-07-17 19:23:12+00:00\n",
      "Processing data for 2024-07-17 19:23:27+00:00\n",
      "Processing data for 2024-07-17 19:23:42+00:00\n",
      "Processing data for 2024-07-17 19:23:57+00:00\n",
      "Processing data for 2024-07-17 19:24:12+00:00\n",
      "Processing data for 2024-07-17 19:24:27+00:00\n",
      "Processing data for 2024-07-17 19:24:42+00:00\n",
      "Processing data for 2024-07-17 19:24:57+00:00\n",
      "Processing data for 2024-07-17 19:25:12+00:00\n",
      "Processing data for 2024-07-17 19:25:27+00:00\n",
      "Processing data for 2024-07-17 19:25:42+00:00\n",
      "Processing data for 2024-07-17 19:25:57+00:00\n",
      "Processing data for 2024-07-17 19:26:12+00:00\n",
      "Processing data for 2024-07-17 19:26:27+00:00\n",
      "Processing data for 2024-07-17 19:26:42+00:00\n",
      "Processing data for 2024-07-17 19:26:57+00:00\n",
      "Processing data for 2024-07-17 19:27:12+00:00\n",
      "Processing data for 2024-07-17 19:27:27+00:00\n",
      "Processing data for 2024-07-17 19:27:42+00:00\n",
      "Processing data for 2024-07-17 19:27:57+00:00\n",
      "Processing data for 2024-07-17 19:28:12+00:00\n",
      "Processing data for 2024-07-17 19:28:27+00:00\n",
      "Processing data for 2024-07-17 19:28:42+00:00\n",
      "Processing data for 2024-07-17 19:28:57+00:00\n",
      "Processing data for 2024-07-17 19:29:12+00:00\n",
      "Processing data for 2024-07-17 19:29:27+00:00\n",
      "Processing data for 2024-07-17 19:29:42+00:00\n",
      "Processing data for 2024-07-17 19:29:57+00:00\n",
      "Processing data for 2024-07-17 19:30:12+00:00\n",
      "Processing data for 2024-07-17 19:30:27+00:00\n",
      "Processing data for 2024-07-17 19:30:42+00:00\n",
      "Processing data for 2024-07-17 19:30:57+00:00\n",
      "Processing data for 2024-07-17 19:31:12+00:00\n",
      "Processing data for 2024-07-17 19:31:27+00:00\n",
      "Processing data for 2024-07-17 19:31:42+00:00\n",
      "Processing data for 2024-07-17 19:31:57+00:00\n",
      "Processing data for 2024-07-17 19:32:12+00:00\n",
      "Processing data for 2024-07-17 19:32:27+00:00\n",
      "Processing data for 2024-07-17 19:32:42+00:00\n",
      "Processing data for 2024-07-17 19:32:57+00:00\n",
      "Processing data for 2024-07-17 19:33:12+00:00\n",
      "Processing data for 2024-07-17 19:33:27+00:00\n",
      "Processing data for 2024-07-17 19:33:42+00:00\n",
      "Processing data for 2024-07-17 19:33:57+00:00\n",
      "Processing data for 2024-07-17 19:34:12+00:00\n",
      "Processing data for 2024-07-17 19:34:27+00:00\n",
      "Processing data for 2024-07-17 19:34:42+00:00\n",
      "Processing data for 2024-07-17 19:34:57+00:00\n",
      "Processing data for 2024-07-17 19:35:12+00:00\n",
      "Processing data for 2024-07-17 19:35:27+00:00\n",
      "Processing data for 2024-07-17 19:35:42+00:00\n",
      "Processing data for 2024-07-17 19:35:57+00:00\n",
      "Processing data for 2024-07-17 19:36:12+00:00\n",
      "Processing data for 2024-07-17 19:36:27+00:00\n",
      "Processing data for 2024-07-17 19:36:42+00:00\n",
      "Processing data for 2024-07-17 19:36:57+00:00\n",
      "Processing data for 2024-07-17 19:37:12+00:00\n",
      "Processing data for 2024-07-17 19:37:27+00:00\n",
      "Processing data for 2024-07-17 19:37:42+00:00\n",
      "Processing data for 2024-07-17 19:37:57+00:00\n",
      "Processing data for 2024-07-17 19:38:12+00:00\n",
      "Processing data for 2024-07-17 19:38:27+00:00\n",
      "Processing data for 2024-07-17 19:38:42+00:00\n",
      "Processing data for 2024-07-17 19:38:57+00:00\n",
      "Processing data for 2024-07-17 19:39:12+00:00\n",
      "Processing data for 2024-07-17 19:39:27+00:00\n",
      "Processing data for 2024-07-17 19:39:42+00:00\n",
      "Processing data for 2024-07-17 19:39:57+00:00\n",
      "Processing data for 2024-07-17 19:40:12+00:00\n",
      "Processing data for 2024-07-17 19:40:27+00:00\n",
      "Processing data for 2024-07-17 19:40:42+00:00\n",
      "Processing data for 2024-07-17 19:40:57+00:00\n",
      "Processing data for 2024-07-17 19:41:12+00:00\n",
      "Processing data for 2024-07-17 19:41:27+00:00\n",
      "Processing data for 2024-07-17 19:41:42+00:00\n",
      "Processing data for 2024-07-17 19:41:57+00:00\n",
      "Processing data for 2024-07-17 19:42:12+00:00\n",
      "Processing data for 2024-07-17 19:42:27+00:00\n",
      "Processing data for 2024-07-17 19:42:42+00:00\n",
      "Processing data for 2024-07-17 19:42:57+00:00\n",
      "Processing data for 2024-07-17 19:43:12+00:00\n",
      "Processing data for 2024-07-17 19:43:27+00:00\n",
      "Processing data for 2024-07-17 19:43:42+00:00\n",
      "Processing data for 2024-07-17 19:43:57+00:00\n",
      "Processing data for 2024-07-17 19:44:12+00:00\n",
      "Processing data for 2024-07-17 19:44:27+00:00\n",
      "Processing data for 2024-07-17 19:44:42+00:00\n",
      "Processing data for 2024-07-17 19:44:57+00:00\n",
      "Processing data for 2024-07-17 19:45:12+00:00\n",
      "Processing data for 2024-07-17 19:45:27+00:00\n",
      "Processing data for 2024-07-17 19:45:42+00:00\n",
      "Processing data for 2024-07-17 19:45:57+00:00\n",
      "Processing data for 2024-07-17 19:46:12+00:00\n",
      "Processing data for 2024-07-17 19:46:27+00:00\n",
      "Processing data for 2024-07-17 19:46:42+00:00\n",
      "Processing data for 2024-07-17 19:46:57+00:00\n",
      "Processing data for 2024-07-17 19:47:12+00:00\n",
      "Processing data for 2024-07-17 19:47:27+00:00\n",
      "Processing data for 2024-07-17 19:47:42+00:00\n",
      "Processing data for 2024-07-17 19:47:57+00:00\n",
      "Processing data for 2024-07-17 19:48:12+00:00\n",
      "Processing data for 2024-07-17 19:48:27+00:00\n",
      "Processing data for 2024-07-17 19:48:42+00:00\n",
      "Processing data for 2024-07-17 19:48:57+00:00\n",
      "Processing data for 2024-07-17 19:49:12+00:00\n",
      "Processing data for 2024-07-17 19:49:27+00:00\n",
      "Processing data for 2024-07-17 19:49:42+00:00\n",
      "Processing data for 2024-07-17 19:49:57+00:00\n",
      "Processing data for 2024-07-17 19:50:12+00:00\n",
      "Processing data for 2024-07-17 19:50:27+00:00\n",
      "Processing data for 2024-07-17 19:50:42+00:00\n",
      "Processing data for 2024-07-17 19:50:57+00:00\n",
      "Processing data for 2024-07-17 19:51:12+00:00\n",
      "Processing data for 2024-07-17 19:51:27+00:00\n",
      "Processing data for 2024-07-17 19:51:42+00:00\n",
      "Processing data for 2024-07-17 19:51:57+00:00\n",
      "Processing data for 2024-07-17 19:52:12+00:00\n",
      "Processing data for 2024-07-17 19:52:27+00:00\n",
      "Processing data for 2024-07-17 19:52:42+00:00\n",
      "Processing data for 2024-07-17 19:52:57+00:00\n",
      "Processing data for 2024-07-17 19:53:12+00:00\n",
      "Processing data for 2024-07-17 19:53:27+00:00\n",
      "Processing data for 2024-07-17 19:53:42+00:00\n",
      "Processing data for 2024-07-17 19:53:57+00:00\n",
      "Processing data for 2024-07-17 19:54:12+00:00\n",
      "Processing data for 2024-07-17 19:54:27+00:00\n",
      "Processing data for 2024-07-17 19:54:42+00:00\n",
      "Processing data for 2024-07-17 19:54:57+00:00\n",
      "Processing data for 2024-07-17 19:55:12+00:00\n",
      "Processing data for 2024-07-17 19:55:27+00:00\n",
      "Processing data for 2024-07-17 19:55:42+00:00\n",
      "Processing data for 2024-07-17 19:55:57+00:00\n",
      "Processing data for 2024-07-17 19:56:12+00:00\n",
      "Processing data for 2024-07-17 19:56:27+00:00\n",
      "Processing data for 2024-07-17 19:56:42+00:00\n",
      "Processing data for 2024-07-17 19:56:57+00:00\n",
      "Processing data for 2024-07-17 19:57:12+00:00\n",
      "Processing data for 2024-07-17 19:57:27+00:00\n",
      "Processing data for 2024-07-17 19:57:42+00:00\n",
      "Processing data for 2024-07-17 19:57:57+00:00\n",
      "Processing data for 2024-07-17 19:58:12+00:00\n",
      "Processing data for 2024-07-17 19:58:27+00:00\n",
      "Processing data for 2024-07-17 19:58:42+00:00\n",
      "Processing data for 2024-07-17 19:58:57+00:00\n",
      "Processing data for 2024-07-17 19:59:12+00:00\n",
      "Processing data for 2024-07-17 19:59:27+00:00\n",
      "Processing data for 2024-07-17 19:59:42+00:00\n",
      "Processing data for 2024-07-17 19:59:57+00:00\n",
      "Processing data for 2024-07-17 20:00:12+00:00\n",
      "Processing data for 2024-07-17 20:00:27+00:00\n",
      "Processing data for 2024-07-17 20:00:42+00:00\n",
      "Processing data for 2024-07-17 20:00:57+00:00\n",
      "Processing data for 2024-07-17 20:01:12+00:00\n",
      "Processing data for 2024-07-17 20:01:27+00:00\n",
      "Processing data for 2024-07-17 20:01:42+00:00\n",
      "Processing data for 2024-07-17 20:01:57+00:00\n",
      "Processing data for 2024-07-17 20:02:12+00:00\n",
      "Processing data for 2024-07-17 20:02:27+00:00\n",
      "Processing data for 2024-07-17 20:02:42+00:00\n",
      "Processing data for 2024-07-17 20:02:57+00:00\n",
      "Processing data for 2024-07-17 20:03:12+00:00\n",
      "Processing data for 2024-07-17 20:03:27+00:00\n",
      "Processing data for 2024-07-17 20:03:42+00:00\n",
      "Processing data for 2024-07-17 20:03:57+00:00\n",
      "Processing data for 2024-07-17 20:04:12+00:00\n",
      "Processing data for 2024-07-17 20:04:27+00:00\n",
      "Processing data for 2024-07-17 20:04:42+00:00\n",
      "Processing data for 2024-07-17 20:04:57+00:00\n",
      "Processing data for 2024-07-17 20:05:12+00:00\n",
      "Processing data for 2024-07-17 20:05:27+00:00\n",
      "Processing data for 2024-07-17 20:05:42+00:00\n",
      "Processing data for 2024-07-17 20:05:57+00:00\n",
      "Processing data for 2024-07-17 20:06:12+00:00\n",
      "Processing data for 2024-07-17 20:06:27+00:00\n",
      "Processing data for 2024-07-17 20:06:42+00:00\n",
      "Processing data for 2024-07-17 20:06:57+00:00\n",
      "Processing data for 2024-07-17 20:07:12+00:00\n",
      "Processing data for 2024-07-17 20:07:27+00:00\n",
      "Processing data for 2024-07-17 20:07:42+00:00\n",
      "Processing data for 2024-07-17 20:07:57+00:00\n",
      "Processing data for 2024-07-17 20:08:12+00:00\n",
      "Processing data for 2024-07-17 20:08:27+00:00\n",
      "Processing data for 2024-07-17 20:08:42+00:00\n",
      "Processing data for 2024-07-17 20:08:57+00:00\n",
      "Processing data for 2024-07-17 20:09:12+00:00\n",
      "Processing data for 2024-07-17 20:09:27+00:00\n",
      "Processing data for 2024-07-17 20:09:42+00:00\n",
      "Processing data for 2024-07-17 20:09:57+00:00\n",
      "Processing data for 2024-07-17 20:10:12+00:00\n",
      "Processing data for 2024-07-17 20:10:27+00:00\n",
      "Processing data for 2024-07-17 20:10:42+00:00\n",
      "Processing data for 2024-07-17 20:10:57+00:00\n",
      "Processing data for 2024-07-17 20:11:12+00:00\n",
      "Processing data for 2024-07-17 20:11:27+00:00\n",
      "Processing data for 2024-07-17 20:11:42+00:00\n",
      "Processing data for 2024-07-17 20:11:57+00:00\n",
      "Processing data for 2024-07-17 20:12:12+00:00\n",
      "Processing data for 2024-07-17 20:12:27+00:00\n",
      "Processing data for 2024-07-17 20:12:42+00:00\n"
     ]
    }
   ],
   "source": [
    "from skyfield.api import load, wgs84, utc\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "\n",
    "def load_data():\n",
    "    stations_url = 'https://celestrak.org/NORAD/elements/gp.php?GROUP=starlink&FORMAT=tle'\n",
    "    satellites = load.tle_file(stations_url)\n",
    "    return satellites\n",
    "\n",
    "def set_observation_time(year, month, day, hour, minute, second):\n",
    "    ts = load.timescale()\n",
    "    return ts.utc(year, month, day, hour, minute, second)\n",
    "\n",
    "def process_observed_data(filename, start_time, merged_data_file):\n",
    "    data = pd.read_csv(filename, sep=',', header=None, names=['Timestamp', 'Y', 'X'])\n",
    "    data['Timestamp'] = pd.to_datetime(data['Timestamp'], utc=True)\n",
    "    interval_start_time = pd.to_datetime(start_time, utc=True)\n",
    "    interval_end_time = interval_start_time + pd.Timedelta(seconds=14)\n",
    "    filtered_data = data[(data['Timestamp'] >= interval_start_time) & (data['Timestamp'] < interval_end_time)]\n",
    "    if filtered_data.empty:\n",
    "        print(\"No data found.\")\n",
    "        return None\n",
    "\n",
    "    merged_data = pd.read_csv(merged_data_file, parse_dates=['Timestamp'])\n",
    "    merged_data['Timestamp'] = pd.to_datetime(merged_data['Timestamp'], utc=True)\n",
    "    merged_filtered_data = merged_data[(merged_data['Timestamp'] >= interval_start_time) & (merged_data['Timestamp'] < interval_end_time)]\n",
    "    \n",
    "    if merged_filtered_data.empty:\n",
    "        print(\"No matching data found in merged_data_file.\")\n",
    "        return None\n",
    "\n",
    "    if len(merged_filtered_data) < 3:\n",
    "        print(\"Not enough data points in merged_filtered_data.\")\n",
    "        return None\n",
    "\n",
    "    start_data = merged_filtered_data.iloc[0]\n",
    "    middle_data = merged_filtered_data.iloc[len(merged_filtered_data)//2]\n",
    "    end_data = merged_filtered_data.iloc[-2]\n",
    "    rotation = -43\n",
    "    positions = [\n",
    "        (start_data['Timestamp'], (90 - start_data['Elevation'], (start_data['Azimuth'] + rotation) % 360)),\n",
    "        (middle_data['Timestamp'], (90 - middle_data['Elevation'], (middle_data['Azimuth'] + rotation) % 360)),\n",
    "        (end_data['Timestamp'], (90 - end_data['Elevation'], (end_data['Azimuth'] + rotation) % 360))\n",
    "    ]\n",
    "    \n",
    "    return positions\n",
    "\n",
    "\n",
    "def calculate_positions_for_satellite(satellite, observer_location, start_time, interval_seconds, step_seconds):\n",
    "    ts = load.timescale()\n",
    "    positions = []\n",
    "    for second in range(0, interval_seconds + 1, step_seconds):\n",
    "        current_time = start_time + timedelta(seconds=second)\n",
    "        difference = satellite - observer_location\n",
    "        topocentric = difference.at(current_time)\n",
    "        alt, az, distance = topocentric.altaz()\n",
    "        if alt.degrees > 20:\n",
    "            positions.append((alt.degrees, az.degrees))\n",
    "    return positions\n",
    "\n",
    "def calculate_direction_vector(point1, point2):\n",
    "    \"\"\"Calculate the direction vector from point1 to point2.\"\"\"\n",
    "    alt_diff = point2[0] - point1[0]\n",
    "    az_diff = azimuth_difference(point2[1], point1[1])\n",
    "    magnitude = math.sqrt(alt_diff**2 + az_diff**2)\n",
    "    return (alt_diff / magnitude, az_diff / magnitude) if magnitude != 0 else (0, 0)\n",
    "\n",
    "def azimuth_difference(az1, az2):\n",
    "    \"\"\"Calculate the smallest difference between two azimuth angles.\"\"\"\n",
    "    diff = abs(az1 - az2) % 360\n",
    "    if diff > 180:\n",
    "        diff = 360 - diff\n",
    "    return diff\n",
    "\n",
    "def calculate_trajectory_distance(observed_positions, satellite_positions):\n",
    "    \"\"\"Calculate the distance measure between observed and satellite trajectories.\"\"\"\n",
    "    altitude_range = 90.0  # Maximum possible altitude difference\n",
    "    azimuth_range = 180.0  # Maximum possible azimuth difference\n",
    "    direction_range = 2.0  # Maximum possible direction difference (since vectors are normalized)\n",
    "    \n",
    "    distance = 0\n",
    "    for i in range(len(observed_positions)):\n",
    "        # Calculate distance between points\n",
    "        alt_deviation = abs(observed_positions[i][0] - satellite_positions[i][0]) / altitude_range\n",
    "        az_deviation = azimuth_difference(observed_positions[i][1], satellite_positions[i][1]) / azimuth_range\n",
    "        distance += alt_deviation + az_deviation\n",
    "    \n",
    "    # Calculate the overall direction vectors\n",
    "    obs_dir_vector = calculate_direction_vector(observed_positions[0], observed_positions[-1])\n",
    "    sat_dir_vector = calculate_direction_vector(satellite_positions[0], satellite_positions[len(observed_positions) - 1])\n",
    "    \n",
    "    # Calculate direction difference\n",
    "    direction_diff = math.sqrt((obs_dir_vector[0] - sat_dir_vector[0])**2 + (obs_dir_vector[1] - sat_dir_vector[1])**2) / direction_range\n",
    "    \n",
    "    # Add the direction difference to the distance measure\n",
    "    total_distance = distance + direction_diff\n",
    "    \n",
    "    return total_distance\n",
    "\n",
    "def find_matching_satellites(satellites, observer_location, observed_positions_with_timestamps):\n",
    "    best_match = None\n",
    "    closest_distance = float('inf')\n",
    "\n",
    "    ts = load.timescale()\n",
    "    \n",
    "    for satellite in satellites:\n",
    "        satellite_positions = []\n",
    "        valid_positions = True\n",
    "        \n",
    "        for observed_time, observed_data in observed_positions_with_timestamps:\n",
    "            # Calculate satellite position at the specific observed timestamp\n",
    "            difference = satellite - observer_location\n",
    "            topocentric = difference.at(ts.utc(observed_time.year, observed_time.month, observed_time.day, observed_time.hour, observed_time.minute, observed_time.second))\n",
    "            alt, az, _ = topocentric.altaz()\n",
    "            \n",
    "            if alt.degrees <= 20:\n",
    "                valid_positions = False\n",
    "                break\n",
    "            \n",
    "            satellite_positions.append((alt.degrees, az.degrees))\n",
    "        \n",
    "        if valid_positions:\n",
    "            total_distance = calculate_trajectory_distance(\n",
    "                [(90 - data[0], data[1]) for _, data in observed_positions_with_timestamps], \n",
    "                satellite_positions\n",
    "            )\n",
    "            \n",
    "            if total_distance < closest_distance:\n",
    "                closest_distance = total_distance\n",
    "                best_match = satellite.name\n",
    "    \n",
    "    return [best_match] if best_match else []\n",
    "\n",
    "def calculate_distance_for_best_match(satellite, observer_location, start_time, interval_seconds):\n",
    "    ts = load.timescale()\n",
    "    distances = []\n",
    "    for second in range(0, interval_seconds + 1):\n",
    "        current_time = start_time + timedelta(seconds=second)\n",
    "        difference = satellite - observer_location\n",
    "        topocentric = difference.at(current_time)\n",
    "        distance = topocentric.distance().km\n",
    "        distances.append(distance)\n",
    "    return distances\n",
    "\n",
    "def main(filename, year, month, day, hour, minute, second, merged_data_file, satellites):\n",
    "    initial_time = set_observation_time(year, month, day, hour, minute, second)\n",
    "    observer_location = wgs84.latlon(latitude_degrees=51.053464, longitude_degrees=4.361142, elevation_m=60)\n",
    "    observed_positions_with_timestamps = process_observed_data(filename, initial_time.utc_strftime('%Y-%m-%dT%H:%M:%SZ'), merged_data_file)\n",
    "    if observed_positions_with_timestamps is None:\n",
    "        return [], [], []\n",
    "\n",
    "    matching_satellites = find_matching_satellites(satellites, observer_location, observed_positions_with_timestamps)\n",
    "    if not matching_satellites:\n",
    "        return observed_positions_with_timestamps, [], []\n",
    "\n",
    "    best_match_satellite = next(sat for sat in satellites if sat.name == matching_satellites[0])\n",
    "    distances = calculate_distance_for_best_match(best_match_satellite, observer_location, initial_time, 14)\n",
    "    \n",
    "    return observed_positions_with_timestamps, matching_satellites, distances\n",
    "\n",
    "def process_intervals(filename, start_year, start_month, start_day, start_hour, start_minute, start_second, end_year, end_month, end_day, end_hour, end_minute, end_second, merged_data_file, satellites):\n",
    "    results = []\n",
    "    \n",
    "    start_time = datetime(start_year, start_month, start_day, start_hour, start_minute, start_second, tzinfo=utc)\n",
    "    end_time = datetime(end_year, end_month, end_day, end_hour, end_minute, end_second, tzinfo=utc)\n",
    "    current_time = start_time\n",
    "    \n",
    "    while current_time <= end_time:\n",
    "        print(f\"Processing data for {current_time}\")\n",
    "        observed_positions_with_timestamps, matching_satellites, distances = main(filename, current_time.year, current_time.month, current_time.day, current_time.hour, current_time.minute, current_time.second, merged_data_file, satellites)\n",
    "        if matching_satellites:\n",
    "            for second in range(15):\n",
    "                if second < len(distances):\n",
    "                    results.append({\n",
    "                        'Timestamp': current_time + timedelta(seconds=second),\n",
    "                        'Connected_Satellite': matching_satellites[0],\n",
    "                        'Distance': distances[second]\n",
    "                    })\n",
    "        current_time += timedelta(seconds=15)\n",
    "    \n",
    "    result_df = pd.DataFrame(results)\n",
    "    return result_df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    filename = 'white_pixel_coordinates_xor.csv'\n",
    "    merged_data_file = 'processed_observed_data.csv'\n",
    "    \n",
    "    # Load satellite data once\n",
    "    satellites = load_data()\n",
    "    \n",
    "    # Process intervals for the specified range of timestamps\n",
    "    result_df = process_intervals(filename, 2024, 7, 17,  18, 7,57, 2024, 7, 17,  20, 12,42, merged_data_file, satellites)\n",
    "\n",
    "    # Load the data from both CSV files\n",
    "    merged_data_df = pd.read_csv(merged_data_file, parse_dates=['Timestamp'])\n",
    "\n",
    "    # Load the existing matched_satellite_data.csv if it exists\n",
    "    if os.path.exists('matched_satellite_data.csv'):\n",
    "        existing_df = pd.read_csv('matched_satellite_data.csv', parse_dates=['Timestamp'])\n",
    "    else:\n",
    "        existing_df = pd.DataFrame()\n",
    "\n",
    "    # Merge the dataframes on Timestamp column\n",
    "    merged_df = pd.merge(merged_data_df, result_df, on='Timestamp', how='inner')\n",
    "\n",
    "    # Append the new data to the existing data\n",
    "    updated_df = pd.concat([existing_df, merged_df]).drop_duplicates(subset=['Timestamp'], keep='last')\n",
    "\n",
    "    # Save the updated dataframe to the CSV file\n",
    "    updated_df.to_csv('matched_satellite_data.csv', index=False)\n",
    "\n",
    "    print(\"Updated data saved to 'matched_satellite_data.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be33f30a-2087-481e-975a-8e65948e9578",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
