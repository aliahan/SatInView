{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba2d7b0b-9ccb-444c-b41c-f6259aff40b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# your UT's orientation\n",
    "_tilt = \n",
    "_rotation_az =\n",
    "_lat=  \n",
    "_lon=\n",
    "_alt=\n",
    "# Srart of first 15 second interval\n",
    "_first_year=\n",
    "_first_month=\n",
    "_first_day=\n",
    "_first_hour=\n",
    "_first_minute=\n",
    "_first_second=\n",
    "# Srart of last 15 second interval\n",
    "_last_year=\n",
    "_last_month=\n",
    "_last_day=\n",
    "_last_hour=\n",
    "_last_minute=\n",
    "_last_second="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a05d608-9f54-4ad9-841c-f3fc46c8c79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def process_observed_data(filename):\n",
    "    data = pd.read_csv(filename, sep=',', header=None, names=['Timestamp', 'Y', 'X'])\n",
    "    data['Timestamp'] = pd.to_datetime(data['Timestamp'], utc=True)\n",
    "    \n",
    "    observer_x, observer_y = 62, 62  # Assume this is the observer's pixel location\n",
    "    pixel_to_degrees = (80/62)  # Conversion factor from pixel to degrees\n",
    "    \n",
    "    positions = []\n",
    "    for index, point in data.iterrows():\n",
    "        dx, dy = point['X'] - observer_x, (123 - point['Y']) - observer_y\n",
    "        radius = np.sqrt(dx**2 + dy**2) * pixel_to_degrees\n",
    "        azimuth = np.degrees(np.arctan2(dx, dy))\n",
    "        # Normalize the azimuth to ensure it's within 0 to 360 degrees\n",
    "        azimuth = (azimuth + 360) % 360\n",
    "        elevation = 90 - radius\n",
    "        positions.append((point['Timestamp'], point['Y'], point['X'], elevation, azimuth))\n",
    "    \n",
    "    df_positions = pd.DataFrame(positions, columns=['Timestamp', 'Y', 'X', 'Elevation', 'Azimuth'])\n",
    "    return df_positions\n",
    "\n",
    "def main(filename):\n",
    "    observed_positions = process_observed_data(filename)\n",
    "    if not observed_positions.empty:\n",
    "        print(observed_positions)\n",
    "        observed_positions.to_csv('processed_observed_data_CHANGE_NAME.csv', index=False)\n",
    "    else:\n",
    "        print(\"No valid observed data found.\")\n",
    "    return observed_positions\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    filename = 'obstruction-data-CHANGE_NAME.csv'\n",
    "    observed_positions = main(filename)\n",
    "    observed_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe45141-8cc9-447a-8aed-086096f0bccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skyfield.api import load, wgs84, utc\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "\n",
    "def load_data():\n",
    "    # make sure to use TLE data from the exact time of data collection\n",
    "    TLE_FILE_PATH = 'starlink-tle-2024-10-12-06-00-00.txt'\n",
    "    satellites = load.tle_file(TLE_FILE_PATH)\n",
    "    return satellites\n",
    "\n",
    "def set_observation_time(year, month, day, hour, minute, second):\n",
    "    ts = load.timescale()\n",
    "    return ts.utc(year, month, day, hour, minute, second)\n",
    "\n",
    "def process_observed_data(filename, start_time, merged_data_file):\n",
    "    data = pd.read_csv(filename, sep=',', header=None, names=['Timestamp', 'Y', 'X'])\n",
    "    data['Timestamp'] = pd.to_datetime(data['Timestamp'], utc=True)\n",
    "    interval_start_time = pd.to_datetime(start_time, utc=True)\n",
    "    interval_end_time = interval_start_time + pd.Timedelta(seconds=14)\n",
    "    filtered_data = data[(data['Timestamp'] >= interval_start_time) & (data['Timestamp'] < interval_end_time)]\n",
    "    if filtered_data.empty:\n",
    "        print(\"No data found.\")\n",
    "        return None\n",
    "\n",
    "    merged_data = pd.read_csv(merged_data_file, parse_dates=['Timestamp'])\n",
    "    merged_data['Timestamp'] = pd.to_datetime(merged_data['Timestamp'], utc=True)\n",
    "    merged_filtered_data = merged_data[(merged_data['Timestamp'] >= interval_start_time) & (merged_data['Timestamp'] < interval_end_time)]\n",
    "    \n",
    "    if merged_filtered_data.empty:\n",
    "        print(\"No matching data found in merged_data_file.\")\n",
    "        return None\n",
    "\n",
    "    if len(merged_filtered_data) < 3:\n",
    "        print(\"Not enough data points in merged_filtered_data.\")\n",
    "        return None\n",
    "\n",
    "    start_data = merged_filtered_data.iloc[0]\n",
    "    middle_data = merged_filtered_data.iloc[len(merged_filtered_data)//2]\n",
    "    end_data = merged_filtered_data.iloc[-2]\n",
    "    rotation = 0\n",
    "    positions = [\n",
    "        (start_data['Timestamp'], (90 - start_data['Elevation'], (start_data['Azimuth'] + rotation) % 360)),\n",
    "        (middle_data['Timestamp'], (90 - middle_data['Elevation'], (middle_data['Azimuth'] + rotation) % 360)),\n",
    "        (end_data['Timestamp'], (90 - end_data['Elevation'], (end_data['Azimuth'] + rotation) % 360))\n",
    "    ]\n",
    "    \n",
    "    return positions\n",
    "\n",
    "# Calculate angular separation between two positions\n",
    "def angular_separation(alt1, az1, alt2, az2):\n",
    "    \"\"\"Calculate the angular separation between two points on a sphere given by altitude and azimuth.\"\"\"\n",
    "    alt1, alt2 = np.radians(alt1), np.radians(alt2)\n",
    "    az1 = (az1 + 360) % 360\n",
    "    az2 = (az2 + 360) % 360\n",
    "    az_diff = np.abs(az1 - az2)\n",
    "    if az_diff > 180:\n",
    "        az_diff = 360 - az_diff\n",
    "    az_diff = np.radians(az_diff)\n",
    "    separation = np.arccos(np.sin(alt1) * np.sin(alt2) + np.cos(alt1) * np.cos(alt2) * np.cos(az_diff))\n",
    "    return np.degrees(separation)\n",
    "\n",
    "# Calculate bearing (direction) between two points\n",
    "def calculate_bearing(alt1, az1, alt2, az2):\n",
    "    alt1, alt2 = np.radians(alt1), np.radians(alt2)\n",
    "    az1, az2 = np.radians(az1), np.radians(az2)\n",
    "    x = np.sin(az2 - az1) * np.cos(alt2)\n",
    "    y = np.cos(alt1) * np.sin(alt2) - np.sin(alt1) * np.cos(alt2) * np.cos(az2 - az1)\n",
    "    bearing = np.arctan2(x, y)\n",
    "    bearing = np.degrees(bearing)\n",
    "    return (bearing + 360) % 360\n",
    "\n",
    "# Calculate bearing difference between two trajectories\n",
    "def calculate_bearing_difference(observed_trajectory, satellite_trajectory):\n",
    "    observed_bearing = calculate_bearing(observed_trajectory[0][0], observed_trajectory[0][1], \n",
    "                                         observed_trajectory[-1][0], observed_trajectory[-1][1])\n",
    "    satellite_bearing = calculate_bearing(satellite_trajectory[0][0], satellite_trajectory[0][1], \n",
    "                                          satellite_trajectory[-1][0], satellite_trajectory[-1][1])\n",
    "    bearing_diff = abs(observed_bearing - satellite_bearing)\n",
    "    if bearing_diff > 180:\n",
    "        bearing_diff = 360 - bearing_diff\n",
    "    return bearing_diff\n",
    "\n",
    "# Calculate the total angular separation and bearing difference\n",
    "def calculate_total_difference(observed_positions, satellite_positions):\n",
    "    total_angular_separation = 0\n",
    "    for i in range(len(observed_positions)):\n",
    "        obs_alt, obs_az = observed_positions[i]\n",
    "        sat_alt, sat_az = satellite_positions[i]\n",
    "        separation = angular_separation(obs_alt, obs_az, sat_alt, sat_az)\n",
    "        total_angular_separation += separation\n",
    "    bearing_diff = calculate_bearing_difference(observed_positions, satellite_positions)\n",
    "    total_difference = total_angular_separation + bearing_diff\n",
    "    return total_difference\n",
    "\n",
    "# Update the find_matching_satellites function to use angular separation and bearing difference\n",
    "def find_matching_satellites(satellites, observer_location, observed_positions_with_timestamps):\n",
    "    best_match = None\n",
    "    closest_total_difference = float('inf')\n",
    "\n",
    "    ts = load.timescale()\n",
    "    \n",
    "    for satellite in satellites:\n",
    "        satellite_positions = []\n",
    "        valid_positions = True\n",
    "        \n",
    "        for observed_time, observed_data in observed_positions_with_timestamps:\n",
    "            difference = satellite - observer_location\n",
    "            topocentric = difference.at(ts.utc(observed_time.year, observed_time.month, observed_time.day, observed_time.hour, observed_time.minute, observed_time.second))\n",
    "            alt, az, _ = topocentric.altaz()\n",
    "            \n",
    "            if alt.degrees <= 20:\n",
    "                valid_positions = False\n",
    "                break\n",
    "            \n",
    "            satellite_positions.append((alt.degrees, az.degrees))\n",
    "        \n",
    "        if valid_positions:\n",
    "            total_difference = calculate_total_difference(\n",
    "                [(90 - data[0], data[1]) for _, data in observed_positions_with_timestamps], \n",
    "                satellite_positions\n",
    "            )\n",
    "            # print(satellite.name, \": \", total_difference)\n",
    "            if total_difference < closest_total_difference:\n",
    "                closest_total_difference = total_difference\n",
    "                best_match = satellite.name\n",
    "    \n",
    "    return [best_match] if best_match else []\n",
    "\n",
    "def calculate_distance_for_best_match(satellite, observer_location, start_time, interval_seconds):\n",
    "    ts = load.timescale()\n",
    "    distances = []\n",
    "    for second in range(0, interval_seconds + 1):\n",
    "        current_time = start_time + timedelta(seconds=second)\n",
    "        difference = satellite - observer_location\n",
    "        topocentric = difference.at(current_time)\n",
    "        distance = topocentric.distance().km\n",
    "        distances.append(distance)\n",
    "    return distances\n",
    "\n",
    "def main(filename, year, month, day, hour, minute, second, merged_data_file, satellites):\n",
    "    initial_time = set_observation_time(year, month, day, hour, minute, second)\n",
    "    observer_location =wgs84.latlon(latitude_degrees=_lat, longitude_degrees= _lon, elevation_m=_alt)\n",
    "    interval_seconds = 15\n",
    "    observed_positions_with_timestamps = process_observed_data(filename, initial_time.utc_strftime('%Y-%m-%dT%H:%M:%SZ'), merged_data_file)\n",
    "    if observed_positions_with_timestamps is None:\n",
    "        return [], [], []\n",
    "\n",
    "    matching_satellites = find_matching_satellites(satellites, observer_location, observed_positions_with_timestamps)\n",
    "    if not matching_satellites:\n",
    "        return observed_positions_with_timestamps, [], []\n",
    "\n",
    "    best_match_satellite = next(sat for sat in satellites if sat.name == matching_satellites[0])\n",
    "    distances = calculate_distance_for_best_match(best_match_satellite, observer_location, initial_time, 14)\n",
    "    \n",
    "    return observed_positions_with_timestamps, matching_satellites, distances\n",
    "\n",
    "def process_intervals(filename, start_year, start_month, start_day, start_hour, start_minute, start_second, end_year, end_month, end_day, end_hour, end_minute, end_second, merged_data_file, satellites):\n",
    "    results = []\n",
    "    \n",
    "    start_time = datetime(start_year, start_month, start_day, start_hour, start_minute, start_second, tzinfo=utc)\n",
    "    end_time = datetime(end_year, end_month, end_day, end_hour, end_minute, end_second, tzinfo=utc)\n",
    "    current_time = start_time\n",
    "    \n",
    "    while current_time <= end_time:\n",
    "        print(f\"Processing data for {current_time}\")\n",
    "        observed_positions_with_timestamps, matching_satellites, distances = main(filename, current_time.year, current_time.month, current_time.day, current_time.hour, current_time.minute, current_time.second, merged_data_file, satellites)\n",
    "        if matching_satellites:\n",
    "            for second in range(15):\n",
    "                if second < len(distances):\n",
    "                    results.append({\n",
    "                        'Timestamp': current_time + timedelta(seconds=second),\n",
    "                        'Connected_Satellite': matching_satellites[0],\n",
    "                        'Distance': distances[second]\n",
    "                    })\n",
    "        current_time += timedelta(seconds=15)\n",
    "    \n",
    "    result_df = pd.DataFrame(results)\n",
    "    return result_df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    filename = 'obstruction-data-CHANGE_NAME.csv'\n",
    "    merged_data_file = 'processed_observed_data_CHANGE_NAME.csv'\n",
    "    \n",
    "    satellites = load_data()\n",
    "    \n",
    "    result_df = process_intervals(filename, _first_year, _first_month, _first_day,  _first_hour, _first_minute,_first_second, _last_year, _last_month, _last_day,  _last_hour, _last_minute,_last_second, merged_data_file, satellites)\n",
    "\n",
    "    merged_data_df = pd.read_csv(merged_data_file, parse_dates=['Timestamp'])\n",
    "\n",
    "    if os.path.exists('serving_satellite_data_CHANGE_NAME.csv'):\n",
    "        existing_df = pd.read_csv('serving_satellite_data_CHANGE_NAME.csv', parse_dates=['Timestamp'])\n",
    "    else:\n",
    "        existing_df = pd.DataFrame()\n",
    "\n",
    "    merged_df = pd.merge(merged_data_df, result_df, on='Timestamp', how='inner')\n",
    "\n",
    "    updated_df = pd.concat([existing_df, merged_df]).drop_duplicates(subset=['Timestamp'], keep='last')\n",
    "\n",
    "    updated_df.to_csv('serving_satellite_data_CHANGE_NAME.csv', index=False)\n",
    "\n",
    "    print(\"Updated data saved to 'serving_satellite_data_CHANGE_NAME.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15416aa-14fb-4f9b-92f1-7591e1f898f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import timedelta\n",
    "import math\n",
    "from skyfield.api import load, wgs84, EarthSatellite\n",
    "import json\n",
    "import os\n",
    "\n",
    "def load_data():\n",
    "    TLE_FILE_PATH = 'starlink-tle-2024-10-12-06-00-00.txt'\n",
    "    satellites = load.tle_file(TLE_FILE_PATH)\n",
    "    print('Loaded', len(satellites), 'satellites')\n",
    "    return satellites\n",
    "\n",
    "def set_observation_time(year, month, day, hour, minute, second):\n",
    "    ts = load.timescale()\n",
    "    return ts.utc(year, month, day, hour, minute, second)\n",
    "\n",
    "def calculate_satellite_positions(satellites, observer_location, observation_time):\n",
    "    locations = []\n",
    "    sats = []\n",
    "    min_elevation = 20\n",
    "    for satellite in satellites:\n",
    "        difference = satellite - observer_location\n",
    "        topocentric = difference.at(observation_time)\n",
    "        alt, az, distance = topocentric.altaz()\n",
    "        if alt.degrees > min_elevation:\n",
    "            loc = [(90 - alt.degrees, np.radians(az.degrees))]\n",
    "            locations.append(loc)\n",
    "            sats.append((satellite, alt, az, distance))\n",
    "    return locations, sats\n",
    "\n",
    "def rotate_points(x, y, angle):\n",
    "    x_rot = x * np.cos(angle) - y * np.sin(angle)\n",
    "    y_rot = x * np.sin(angle) + y * np.cos(angle)\n",
    "    return x_rot, y_rot\n",
    "\n",
    "def find_fov_sats(timestamps, satellites, observer_location, tilt_deg, rotation_deg):\n",
    "    fov_data = []\n",
    "\n",
    "    base_radius = 60\n",
    "    center_shift = tilt_deg\n",
    "    x_radius = base_radius\n",
    "    y_radius = math.sqrt(base_radius**2 - tilt_deg**2)\n",
    "\n",
    "    for timestamp in timestamps:\n",
    "        observation_time = set_observation_time(timestamp.year, timestamp.month, timestamp.day, timestamp.hour, timestamp.minute, timestamp.second)\n",
    "        locations, sats = calculate_satellite_positions(satellites, observer_location, observation_time)\n",
    "        \n",
    "        fov_sats = []\n",
    "        for loc, sat in zip(locations, sats):\n",
    "            loc = np.array(loc)\n",
    "            r = loc[:, 0]\n",
    "            angle = loc[:, 1]\n",
    "            inside = False\n",
    "            for r_i, angle_i in zip(r, angle):\n",
    "                x_point = r_i * np.cos(angle_i)\n",
    "                y_point = r_i * np.sin(angle_i)\n",
    "                x_point_rot, y_point_rot = rotate_points(x_point, y_point, -np.deg2rad(rotation_deg))\n",
    "                x_point_rot -= center_shift\n",
    "                if (x_point_rot**2 / x_radius**2) + (y_point_rot**2 / y_radius**2) <= 1:\n",
    "                    inside = True\n",
    "                    break\n",
    "            if inside:\n",
    "                fov_sats.append({\n",
    "                    'Name': sat[0].name,\n",
    "                    'Azimuth': sat[2].degrees,\n",
    "                    'Elevation': sat[1].degrees,\n",
    "                    'Distance': sat[3].km,\n",
    "                    'Inclination': sat[0].model.inclo * 180.0 / np.pi\n",
    "                })\n",
    "        fov_data.append({\n",
    "            'Timestamp': timestamp.isoformat(),\n",
    "            'Satellites': fov_sats\n",
    "        })\n",
    "\n",
    "    return fov_data\n",
    "\n",
    "def save_fov_data(fov_data, filename='fov_data_ulu.json'):\n",
    "    with open(filename, 'w') as file:\n",
    "        json.dump(fov_data, file)\n",
    "\n",
    "def load_fov_data(filename='fov_data_ulu.json'):\n",
    "    if os.path.exists(filename):\n",
    "        with open(filename, 'r') as file:\n",
    "            fov_data = json.load(file)\n",
    "        print('Loaded fov_data from file')\n",
    "        return fov_data\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def calculate_cdf(data):\n",
    "    sorted_data = np.sort(data)\n",
    "    cdf = np.arange(1, len(sorted_data) + 1) / len(sorted_data)\n",
    "    return sorted_data, cdf\n",
    "\n",
    "def plot_cdfs(fov_data, matched_data):\n",
    "    azimuths = []\n",
    "    elevations = []\n",
    "    distances = []\n",
    "    inclinations = []\n",
    "\n",
    "    for entry in fov_data:\n",
    "        for sat in entry['Satellites']:\n",
    "            azimuths.append(sat['Azimuth'])\n",
    "            elevations.append(sat['Elevation'])\n",
    "            distances.append(sat['Distance'])\n",
    "            inclinations.append(sat['Inclination'])\n",
    "\n",
    "    azimuth_sorted, azimuth_cdf = calculate_cdf(azimuths)\n",
    "    elevation_sorted, elevation_cdf = calculate_cdf(elevations)\n",
    "    distance_sorted, distance_cdf = calculate_cdf(distances)\n",
    "    inclination_sorted, inclination_cdf = calculate_cdf(inclinations)\n",
    "\n",
    "    # Plot for available satellites\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    ax.plot(distance_sorted, distance_cdf, linestyle='-', color='blue', label='Available Satellites Distance')\n",
    "    ax.set_title('CDF of Distance', fontsize=24)\n",
    "    ax.set_xlabel('Distance (km)', fontsize=24)\n",
    "    ax.set_ylabel('CDF', fontsize=24)\n",
    "    ax.grid(True)\n",
    "    ax.legend(fontsize=16)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=24)\n",
    "    matched_distances = matched_data['Distance'].dropna()\n",
    "    matched_distance_sorted, matched_distance_cdf = calculate_cdf(matched_distances)\n",
    "    ax.plot(matched_distance_sorted, matched_distance_cdf, linestyle='-', color='red', label='Matched Satellites Distance')\n",
    "    ax.legend(fontsize=18)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('CDF_Distance.png')\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    ax.plot(elevation_sorted, elevation_cdf, linestyle='-', color='blue', label='Available Satellites Elevation')\n",
    "    ax.set_title('CDF of Elevation', fontsize=24)\n",
    "    ax.set_xlabel('Elevation (degrees)', fontsize=24)\n",
    "    ax.set_ylabel('CDF', fontsize=24)\n",
    "    ax.grid(True)\n",
    "    ax.legend(fontsize=16)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=24)\n",
    "    matched_elevations = matched_data['Elevation'].dropna()\n",
    "    matched_elevation_sorted, matched_elevation_cdf = calculate_cdf(matched_elevations)\n",
    "    ax.plot(matched_elevation_sorted, matched_elevation_cdf, linestyle='-', color='red', label='Matched Satellites Elevation')\n",
    "    ax.legend(fontsize=18)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('CDF_Elevation.png')\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    ax.plot(azimuth_sorted, azimuth_cdf, linestyle='-', color='blue', label='Available Satellites Azimuth')\n",
    "    ax.set_title('CDF of Azimuth', fontsize=24)\n",
    "    ax.set_xlabel('Azimuth (degrees)', fontsize=24)\n",
    "    ax.set_ylabel('CDF', fontsize=24)\n",
    "    ax.grid(True)\n",
    "    ax.legend(fontsize=16)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=24)\n",
    "    matched_azimuths = matched_data['Azimuth'].dropna()\n",
    "    matched_azimuths = (matched_azimuths)%360\n",
    "    matched_azimuth_sorted, matched_azimuth_cdf = calculate_cdf(matched_azimuths)\n",
    "    ax.plot(matched_azimuth_sorted, matched_azimuth_cdf, linestyle='-', color='red', label='Matched Satellites Azimuth')\n",
    "    ax.legend(fontsize=18)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('CDF_Azimuth.png')\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    ax.plot(inclination_sorted, inclination_cdf, linestyle='-', color='blue', label='Available Satellites Inclination')\n",
    "    ax.set_title('CDF of Inclination', fontsize=24)\n",
    "    ax.set_xlabel('Inclination (degrees)', fontsize=24)\n",
    "    ax.set_ylabel('CDF', fontsize=24)\n",
    "    ax.grid(True)\n",
    "    ax.legend(fontsize=16)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=24)\n",
    "    matched_inclinations = matched_data['Inclination'].dropna()\n",
    "    matched_inclination_sorted, matched_inclination_cdf = calculate_cdf(matched_inclinations)\n",
    "    ax.plot(matched_inclination_sorted, matched_inclination_cdf, linestyle='-', color='red', label='Matched Satellites Inclination')\n",
    "    ax.legend(fontsize=18)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('CDF_Inclination.png')\n",
    "\n",
    "# Load the data\n",
    "file_path = 'serving_satellite_data_CHANGE_NAME.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "# Convert Timestamp to datetime\n",
    "data['Timestamp'] = pd.to_datetime(data['Timestamp'])\n",
    "# data = data.loc[:28]\n",
    "# Filter the timestamps with the required seconds\n",
    "filtered_data = data[data['Timestamp'].dt.second.isin([12, 27, 42, 57])]\n",
    "\n",
    "# Load satellite data\n",
    "satellites = load_data()\n",
    "\n",
    "# Observer location (hardcoded based on previous input)\n",
    "observer_location = wgs84.latlon(latitude_degrees=_lat, longitude_degrees= _lon, elevation_m=_alt)\n",
    "\n",
    "# Load fov_data if it exists, otherwise calculate it\n",
    "fov_data = load_fov_data()\n",
    "\n",
    "if fov_data is None:\n",
    "    # Find satellites in the FOV for the filtered timestamps\n",
    "    fov_data = find_fov_sats(filtered_data['Timestamp'].unique(), satellites, observer_location, _tilt, _rotation_az)\n",
    "    save_fov_data(fov_data)\n",
    "\n",
    "# Load TLE data for inclination\n",
    "satellites = load.tle_file('starlink-tle-2024-10-12-06-00-00.txt')\n",
    "inclinations = {sat.name: sat.model.inclo * 180.0 / np.pi for sat in satellites}\n",
    "\n",
    "# Add inclination data to the matched dataframe\n",
    "data['Inclination'] = data['Connected_Satellite'].map(inclinations)\n",
    "\n",
    "# Plot CDFs\n",
    "plot_cdfs(fov_data, data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2eb7d20-7631-4d24-a5f1-5524eb0ff206",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
